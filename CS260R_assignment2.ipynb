{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/8Dis-like/UCLALearning/blob/main/CS260R_assignment2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "455f8adf",
      "metadata": {
        "id": "455f8adf"
      },
      "source": [
        "# Assignment 2: Deep Q Learning and Policy Gradient\n",
        "\n",
        "*CS260R: Reinforcement Learning. Department of Computer Science at University of California, Los Angeles.\n",
        "Course Instructor: Professor Bolei ZHOU. Assignment author: Zhenghao PENG.*\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5ecc5685",
      "metadata": {
        "id": "5ecc5685"
      },
      "source": [
        "| Student Name | Student ID |\n",
        "| :----: | :----: |\n",
        "| Hao Zhang | 206548281 |\n",
        "\n",
        "------"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b55e080e",
      "metadata": {
        "id": "b55e080e"
      },
      "source": [
        "Welcome to the assignment 2 of our RL course. This assignment consisits of three parts:\n",
        "\n",
        "* Section 2: Implement Q learning in tabular setting (20 points)\n",
        "* Section 3: Implement Deep Q Network with pytorch (30 points)\n",
        "* Section 4: Implement policy gradient method REINFORCE with pytorch (30 points)\n",
        "* Section 5: Implement policy gradient method with baseline (20 points)\n",
        "\n",
        "Section 0 and Section 1 set up the dependencies and prepare some useful functions.\n",
        "\n",
        "The experiments we'll conduct and their expected goals:\n",
        "\n",
        "1. Naive Q learning in FrozenLake &emsp; (should solve)\n",
        "2. DQN in CartPole &emsp; (should solve)\n",
        "3. DQN in MetaDrive-Easy &emsp; (should solve)\n",
        "4. Policy Gradient w/o baseline in CartPole (w/ and w/o advantage normalization) &emsp; (should solve)\n",
        "5. Policy Gradient w/o baseline in MetaDrive-Easy &emsp; (should solve)\n",
        "6. Policy Gradient w/ baseline in CartPole (w/ advantage normalization) &emsp; (should solve)\n",
        "7. Policy Gradient w/ baseline in MetaDrive-Easy &emsp; (should solve)\n",
        "8. Policy Gradient w/ baseline in MetaDrive-Hard &emsp; (>20 return)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3feea3d2",
      "metadata": {
        "id": "3feea3d2"
      },
      "source": [
        "## Section 0: Dependencies\n",
        "\n",
        "Please install the following dependencies.\n",
        "\n",
        "\n",
        "### Notes on MetaDrive\n",
        "\n",
        "MetaDrive is a lightweight driving simulator which we will use for DQN and Policy Gradient methods. We suggest using Colab or Linux for running MetaDrive.\n",
        "\n",
        "Please ignore this warning from MetaDrive: `WARNING:root:BaseEngine is not launched, fail to sync seed to engine!`\n",
        "\n",
        "### Notes on Colab\n",
        "\n",
        "We have several cells used for installing dependencies for Colab only. Please make sure they are run properly.\n",
        "\n",
        "You don't need to install python packages again and again after **restarting the runtime**, since the Colab instance still remembers the python envionment after you installing packages for the first time. But you do need to rerun those packages installation script after you **reconnecting to the runtime** (which means Google assigns a new machine to you and thus the python environment is new)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b170cda",
      "metadata": {
        "id": "9b170cda"
      },
      "outputs": [],
      "source": [
        "RUNNING_IN_COLAB = 'google.colab' in str(get_ipython())  # Detect if it is running in Colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9098b4a3-1f4e-4ffd-b6cb-dbec4ede65f4",
      "metadata": {
        "scrolled": true,
        "id": "9098b4a3-1f4e-4ffd-b6cb-dbec4ede65f4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6df37bee-5c0d-4cc5-daaf-c271acdd10ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.12/dist-packages (24.1.2)\n",
            "Collecting pip\n",
            "  Downloading pip-26.0.1-py3-none-any.whl.metadata (4.7 kB)\n",
            "Downloading pip-26.0.1-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 24.1.2\n",
            "    Uninstalling pip-24.1.2:\n",
            "      Successfully uninstalled pip-24.1.2\n",
            "Successfully installed pip-26.0.1\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (1.16.3)\n",
            "Collecting gymnasium<0.29\n",
            "  Downloading gymnasium-0.28.1-py3-none-any.whl.metadata (9.2 kB)\n",
            "Collecting jax-jumpy>=1.0.0 (from gymnasium<0.29)\n",
            "  Downloading jax_jumpy-1.0.0-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium<0.29) (3.1.2)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium<0.29) (4.15.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from gymnasium<0.29) (0.0.4)\n",
            "Downloading gymnasium-0.28.1-py3-none-any.whl (925 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m925.5/925.5 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jax_jumpy-1.0.0-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: jax-jumpy, gymnasium\n",
            "\u001b[2K  Attempting uninstall: gymnasium\n",
            "\u001b[2K    Found existing installation: gymnasium 1.2.3\n",
            "\u001b[2K    Uninstalling gymnasium-1.2.3:\n",
            "\u001b[2K      Successfully uninstalled gymnasium-1.2.3\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [gymnasium]\n",
            "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "dopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.28.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed gymnasium-0.28.1 jax-jumpy-1.0.0\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cpu)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.24.0+cpu)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.3)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Collecting mediapy\n",
            "  Downloading mediapy-1.2.6-py3-none-any.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.12/dist-packages (from mediapy) (7.34.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from mediapy) (3.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from mediapy) (2.0.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from mediapy) (11.3.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.12/dist-packages (from ipython->mediapy) (75.2.0)\n",
            "Collecting jedi>=0.16 (from ipython->mediapy)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.12/dist-packages (from ipython->mediapy) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.12/dist-packages (from ipython->mediapy) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.12/dist-packages (from ipython->mediapy) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from ipython->mediapy) (3.0.52)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.12/dist-packages (from ipython->mediapy) (2.19.2)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.12/dist-packages (from ipython->mediapy) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.12/dist-packages (from ipython->mediapy) (0.2.1)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.12/dist-packages (from ipython->mediapy) (4.9.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->mediapy) (0.5.3)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.12/dist-packages (from jedi>=0.16->ipython->mediapy) (0.8.5)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.12/dist-packages (from pexpect>4.3->ipython->mediapy) (0.7.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapy) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapy) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapy) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapy) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapy) (26.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapy) (3.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapy) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib->mediapy) (1.17.0)\n",
            "Downloading mediapy-1.2.6-py3-none-any.whl (27 kB)\n",
            "Downloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: jedi, mediapy\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [mediapy]\n",
            "\u001b[1A\u001b[2KSuccessfully installed jedi-0.19.2 mediapy-1.2.6\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.2)\n"
          ]
        }
      ],
      "source": [
        "# Similar to AS1\n",
        "\n",
        "!pip install -U pip\n",
        "!pip install numpy scipy \"gymnasium<0.29\"\n",
        "!pip install torch torchvision\n",
        "!pip install mediapy\n",
        "!pip install tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b05b5d4",
      "metadata": {
        "id": "5b05b5d4",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c74e9d03-3aaf-40d5-aba2-0dec14009777"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/metadriverse/metadrive\n",
            "  Cloning https://github.com/metadriverse/metadrive to /tmp/pip-req-build-50fg9aps\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/metadriverse/metadrive /tmp/pip-req-build-50fg9aps\n",
            "  Resolved https://github.com/metadriverse/metadrive to commit 85e5dadc6c7436d324348f6e3d8f8e680c06b4db\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from metadrive-simulator==0.4.3) (2.32.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from metadrive-simulator==0.4.3) (3.10.0)\n",
            "Requirement already satisfied: pygame in /usr/local/lib/python3.12/dist-packages (from metadrive-simulator==0.4.3) (2.6.1)\n",
            "Collecting yapf (from metadrive-simulator==0.4.3)\n",
            "  Downloading yapf-0.43.0-py3-none-any.whl.metadata (46 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from metadrive-simulator==0.4.3) (4.67.2)\n",
            "Collecting progressbar (from metadrive-simulator==0.4.3)\n",
            "  Downloading progressbar-2.5.tar.gz (10 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (from metadrive-simulator==0.4.3) (11.3.0)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.12/dist-packages (from metadrive-simulator==0.4.3) (6.0.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from metadrive-simulator==0.4.3) (5.9.5)\n",
            "Requirement already satisfied: shapely in /usr/local/lib/python3.12/dist-packages (from metadrive-simulator==0.4.3) (2.1.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from metadrive-simulator==0.4.3) (3.20.3)\n",
            "Requirement already satisfied: Pygments in /usr/local/lib/python3.12/dist-packages (from metadrive-simulator==0.4.3) (2.19.2)\n",
            "Requirement already satisfied: mediapy in /usr/local/lib/python3.12/dist-packages (from metadrive-simulator==0.4.3) (1.2.6)\n",
            "Collecting panda3d>=1.10.14 (from metadrive-simulator==0.4.3)\n",
            "  Downloading panda3d-1.10.16-cp312-cp312-manylinux2014_x86_64.whl.metadata (3.3 kB)\n",
            "Collecting panda3d-gltf<1.0,>=0.13 (from metadrive-simulator==0.4.3)\n",
            "  Downloading panda3d_gltf-0.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: gymnasium>=0.28 in /usr/local/lib/python3.12/dist-packages (from metadrive-simulator==0.4.3) (0.28.1)\n",
            "Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.12/dist-packages (from metadrive-simulator==0.4.3) (2.0.2)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (from metadrive-simulator==0.4.3) (4.13.0.90)\n",
            "Collecting panda3d-simplepbr>=0.6 (from panda3d-gltf<1.0,>=0.13->metadrive-simulator==0.4.3)\n",
            "  Downloading panda3d_simplepbr-0.13.1-py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: jax-jumpy>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium>=0.28->metadrive-simulator==0.4.3) (1.0.0)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium>=0.28->metadrive-simulator==0.4.3) (3.1.2)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium>=0.28->metadrive-simulator==0.4.3) (4.15.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from gymnasium>=0.28->metadrive-simulator==0.4.3) (0.0.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->metadrive-simulator==0.4.3) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->metadrive-simulator==0.4.3) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->metadrive-simulator==0.4.3) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->metadrive-simulator==0.4.3) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->metadrive-simulator==0.4.3) (26.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->metadrive-simulator==0.4.3) (3.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->metadrive-simulator==0.4.3) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib->metadrive-simulator==0.4.3) (1.17.0)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.12/dist-packages (from mediapy->metadrive-simulator==0.4.3) (7.34.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.12/dist-packages (from ipython->mediapy->metadrive-simulator==0.4.3) (75.2.0)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.12/dist-packages (from ipython->mediapy->metadrive-simulator==0.4.3) (0.19.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.12/dist-packages (from ipython->mediapy->metadrive-simulator==0.4.3) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.12/dist-packages (from ipython->mediapy->metadrive-simulator==0.4.3) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.12/dist-packages (from ipython->mediapy->metadrive-simulator==0.4.3) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from ipython->mediapy->metadrive-simulator==0.4.3) (3.0.52)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.12/dist-packages (from ipython->mediapy->metadrive-simulator==0.4.3) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.12/dist-packages (from ipython->mediapy->metadrive-simulator==0.4.3) (0.2.1)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.12/dist-packages (from ipython->mediapy->metadrive-simulator==0.4.3) (4.9.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->mediapy->metadrive-simulator==0.4.3) (0.5.3)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.12/dist-packages (from jedi>=0.16->ipython->mediapy->metadrive-simulator==0.4.3) (0.8.5)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.12/dist-packages (from pexpect>4.3->ipython->mediapy->metadrive-simulator==0.4.3) (0.7.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->metadrive-simulator==0.4.3) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->metadrive-simulator==0.4.3) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->metadrive-simulator==0.4.3) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->metadrive-simulator==0.4.3) (2026.1.4)\n",
            "Requirement already satisfied: platformdirs>=3.5.1 in /usr/local/lib/python3.12/dist-packages (from yapf->metadrive-simulator==0.4.3) (4.5.1)\n",
            "Downloading panda3d_gltf-0.15.0-py3-none-any.whl (26 kB)\n",
            "Downloading panda3d-1.10.16-cp312-cp312-manylinux2014_x86_64.whl (53.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.9/53.9 MB\u001b[0m \u001b[31m39.4 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading panda3d_simplepbr-0.13.1-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m78.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading yapf-0.43.0-py3-none-any.whl (256 kB)\n",
            "Building wheels for collected packages: metadrive-simulator, progressbar\n",
            "  Building wheel for metadrive-simulator (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for metadrive-simulator: filename=metadrive_simulator-0.4.3-py3-none-any.whl size=55042231 sha256=c4e5b0b422c9bac4565820cfbdf71d0433be9a197bfaefdcf0cb5aed5e35d3b5\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-btxt97ps/wheels/4c/6f/ba/b15e9b4ccec3b93162955ce2cb0df2ff48d69194dcee91397b\n",
            "  Building wheel for progressbar (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for progressbar: filename=progressbar-2.5-py3-none-any.whl size=12144 sha256=6e84800c764bb2a88b870e26a4d3cb144711ac3931bb5028aa3d946c8efc5544\n",
            "  Stored in directory: /root/.cache/pip/wheels/a5/4d/c7/f3cf0f75c746c219090060131fe00f1523cc2c5484991f4030\n",
            "Successfully built metadrive-simulator progressbar\n",
            "Installing collected packages: progressbar, panda3d, yapf, panda3d-simplepbr, panda3d-gltf, metadrive-simulator\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6/6\u001b[0m [metadrive-simulator]\n",
            "\u001b[1A\u001b[2KSuccessfully installed metadrive-simulator-0.4.3 panda3d-1.10.16 panda3d-gltf-0.15.0 panda3d-simplepbr-0.13.1 progressbar-2.5 yapf-0.43.0\n"
          ]
        }
      ],
      "source": [
        "# Install MetaDrive, a lightweight driving simulator\n",
        "\n",
        "import sys\n",
        "\n",
        "!pip install \"git+https://github.com/metadriverse/metadrive\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "IlCJY9seS7RB",
      "metadata": {
        "id": "IlCJY9seS7RB",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47ad5772-508e-498d-9831-3296b6c9037e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start to profile the efficiency of MetaDrive with 1000 maps and ~4 vehicles!\n",
            "\u001b[38;20m[INFO] Environment: MetaDriveEnv\u001b[0m\n",
            "\u001b[38;20m[INFO] MetaDrive version: 0.4.3\u001b[0m\n",
            "\u001b[38;20m[INFO] Sensors: [lidar: Lidar(), side_detector: SideDetector(), lane_line_detector: LaneLineDetector()]\u001b[0m\n",
            "\u001b[38;20m[INFO] Render Mode: none\u001b[0m\n",
            "\u001b[38;20m[INFO] Horizon (Max steps per agent): 1000\u001b[0m\n",
            "\u001b[33;20m[WARNING] Assets folder doesn't exist. Begin to download assets... (base_engine.py:773)\u001b[0m\n",
            "\u001b[38;20m[INFO] Pull assets from https://github.com/metadriverse/metadrive/releases/download/MetaDrive-0.4.3/assets.zip to /usr/local/lib/python3.12/dist-packages/metadrive/assets.zip\u001b[0m\n",
            "100% ||\n",
            "\u001b[38;20m[INFO] Extracting assets.\u001b[0m\n",
            "\u001b[38;20m[INFO] Successfully download assets, version: 0.4.3. MetaDrive version: 0.4.3\u001b[0m\n",
            "\u001b[38;20m[INFO] Known Pipes: glxGraphicsPipe\u001b[0m\n",
            "\u001b[38;20m[INFO] Start Scenario Index: 1010, Num Scenarios : 1000\u001b[0m\n",
            "Finish 100/100 simulation steps. Time elapse: 0.8669. Average FPS: 199.2116, Average number of vehicles: 3.0000\n",
            "Total Time Elapse: 0.867, average FPS: 199.139, average number of vehicles: 3.000.\n"
          ]
        }
      ],
      "source": [
        "# Test whether MetaDrive is properly installed. The test is passed if no error is shown.\n",
        "!python -m metadrive.examples.profile_metadrive --num-steps 100"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9612bfe5",
      "metadata": {
        "id": "9612bfe5"
      },
      "source": [
        "## Section 1: Building abstract class and helper functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9064ac72",
      "metadata": {
        "id": "9064ac72"
      },
      "outputs": [],
      "source": [
        "# Run this cell without modification\n",
        "\n",
        "# Import some packages that we need to use\n",
        "import mediapy as media\n",
        "import gymnasium as gym\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from gymnasium.error import Error\n",
        "from gymnasium import logger\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from IPython.display import clear_output\n",
        "import copy\n",
        "import time\n",
        "import pygame\n",
        "import logging\n",
        "import tqdm\n",
        "\n",
        "logging.basicConfig(format='[%(levelname)s] %(message)s')\n",
        "logger = logging.getLogger()\n",
        "logger.setLevel(logging.INFO)\n",
        "\n",
        "\n",
        "def wait(sleep=0.2):\n",
        "    clear_output(wait=True)\n",
        "    time.sleep(sleep)\n",
        "\n",
        "\n",
        "def merge_config(new_config, old_config):\n",
        "    \"\"\"Merge the user-defined config with default config\"\"\"\n",
        "    config = copy.deepcopy(old_config)\n",
        "    if new_config is not None:\n",
        "        config.update(new_config)\n",
        "    return config\n",
        "\n",
        "\n",
        "def test_random_policy(policy, env):\n",
        "    _acts = set()\n",
        "    for i in range(1000):\n",
        "        act = policy(0)\n",
        "        _acts.add(act)\n",
        "        assert env.action_space.contains(act), \"Out of the bound!\"\n",
        "    if len(_acts) != 1:\n",
        "        print(\n",
        "            \"[HINT] Though we call self.policy a 'random policy', \" \\\n",
        "            \"we find that generating action randomly during initialization \" \\\n",
        "            \"and then sticking with it when update values lead to better \" \\\n",
        "            \"performance. Using purely random policy is not even work! \"\n",
        "        )\n",
        "\n",
        "\n",
        "# We register a non-slippery version of FrozenLake environment.\n",
        "try:\n",
        "    gym.register(\n",
        "        id='FrozenLakeNotSlippery-v1',\n",
        "        entry_point='gymnasium.envs.toy_text:FrozenLakeEnv',\n",
        "        kwargs={'map_name': '4x4', 'is_slippery': False},\n",
        "        max_episode_steps=200,\n",
        "        reward_threshold=0.78,  # optimum = .8196\n",
        "    )\n",
        "except Error:\n",
        "    print(\"The environment is registered already.\")\n",
        "\n",
        "\n",
        "def _render_helper(env, sleep=0.1):\n",
        "    ret = env.render()\n",
        "    if sleep:\n",
        "        wait(sleep=sleep)\n",
        "    return ret\n",
        "\n",
        "\n",
        "def animate(img_array, fps=None):\n",
        "    \"\"\"A function that can generate video and show in Notebook.\"\"\"\n",
        "    media.show_video(img_array, fps=fps)\n",
        "\n",
        "\n",
        "def evaluate(policy, num_episodes=1, seed=0, env_name='FrozenLake8x8-v1',\n",
        "             render=None, existing_env=None, max_episode_length=1000,\n",
        "             sleep=0.0, verbose=False):\n",
        "    \"\"\"This function evaluates the given policy and return the mean episodic\n",
        "    reward.\n",
        "    :param policy: a function whose input is the observation\n",
        "    :param num_episodes: number of episodes you wish to run\n",
        "    :param seed: the random seed\n",
        "    :param env_name: the name of the environment\n",
        "    :param render: a boolean flag indicating whether to render policy\n",
        "    :return: the averaged episode reward of the given policy.\n",
        "    \"\"\"\n",
        "    if existing_env is None:\n",
        "        render_mode = render if render else None\n",
        "        env = gym.make(env_name, render_mode=render)\n",
        "    else:\n",
        "        env = existing_env\n",
        "    try:\n",
        "        rewards = []\n",
        "        frames = []\n",
        "        succ_rate = []\n",
        "        if render:\n",
        "            num_episodes = 1\n",
        "        for i in range(num_episodes):\n",
        "            obs, info = env.reset(seed=seed + i)\n",
        "            act = policy(obs)\n",
        "            ep_reward = 0\n",
        "            for step_count in range(max_episode_length):\n",
        "                obs, reward, terminated, truncated, info = env.step(act)\n",
        "                done = terminated or truncated\n",
        "\n",
        "                act = policy(obs)\n",
        "                ep_reward += reward\n",
        "\n",
        "                if verbose and step_count % 50 == 0:\n",
        "                    print(\"Evaluating {}/{} episodes. We are in {}/{} steps. Current episode reward: {:.3f}\".format(\n",
        "                        i + 1, num_episodes, step_count + 1, max_episode_length, ep_reward\n",
        "                    ))\n",
        "\n",
        "                if render == \"ansi\":\n",
        "                    print(_render_helper(env, sleep))\n",
        "                elif render:\n",
        "                    frames.append(_render_helper(env, sleep))\n",
        "                if done:\n",
        "                    break\n",
        "            rewards.append(ep_reward)\n",
        "            if \"arrive_dest\" in info:\n",
        "                succ_rate.append(float(info[\"arrive_dest\"]))\n",
        "        if render:\n",
        "            env.close()\n",
        "    except Exception as e:\n",
        "        env.close()\n",
        "        raise e\n",
        "    finally:\n",
        "        env.close()\n",
        "    eval_dict = {\"frames\": frames}\n",
        "    if succ_rate:\n",
        "        eval_dict[\"success_rate\"] = sum(succ_rate) / len(succ_rate)\n",
        "    return np.mean(rewards), eval_dict\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d21c8c84",
      "metadata": {
        "id": "d21c8c84"
      },
      "outputs": [],
      "source": [
        "# Run this cell without modification\n",
        "\n",
        "DEFAULT_CONFIG = dict(\n",
        "    seed=0,\n",
        "    max_iteration=20000,\n",
        "    max_episode_length=200,\n",
        "    evaluate_interval=10,\n",
        "    evaluate_num_episodes=10,\n",
        "    learning_rate=0.001,\n",
        "    gamma=0.8,\n",
        "    eps=0.3,\n",
        "    env_name='FrozenLakeNotSlippery-v1'\n",
        ")\n",
        "\n",
        "\n",
        "class AbstractTrainer:\n",
        "    \"\"\"This is the abstract class for value-based RL trainer. We will inherent\n",
        "    the new trainer from this class, so that we can reuse the code.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, config):\n",
        "        self.config = merge_config(config, DEFAULT_CONFIG)\n",
        "\n",
        "        # Create the environment\n",
        "        self.env_name = self.config['env_name']\n",
        "        self.env = gym.make(self.env_name)\n",
        "\n",
        "        # Apply the random seed\n",
        "        self.seed = self.config[\"seed\"]\n",
        "        np.random.seed(self.seed)\n",
        "        self.env.reset(seed=self.seed)\n",
        "\n",
        "        # We set self.obs_dim to the number of possible observations\n",
        "        # if observation space is discrete, otherwise the number\n",
        "        # of observation's dimensions. The same applies to self.act_dim.\n",
        "        if isinstance(self.env.observation_space, gym.spaces.box.Box):\n",
        "            assert len(self.env.observation_space.shape) == 1\n",
        "            self.obs_dim = self.env.observation_space.shape[0]\n",
        "            self.discrete_obs = False\n",
        "        elif isinstance(self.env.observation_space,\n",
        "                        gym.spaces.discrete.Discrete):\n",
        "            self.obs_dim = self.env.observation_space.n\n",
        "            self.discrete_obs = True\n",
        "        else:\n",
        "            raise ValueError(\"Wrong observation space!\")\n",
        "\n",
        "        if isinstance(self.env.action_space, gym.spaces.box.Box):\n",
        "            assert len(self.env.action_space.shape) == 1\n",
        "            self.act_dim = self.env.action_space.shape[0]\n",
        "        elif isinstance(self.env.action_space, gym.spaces.discrete.Discrete):\n",
        "            self.act_dim = self.env.action_space.n\n",
        "        else:\n",
        "            raise ValueError(\"Wrong action space! {}\".format(self.env.action_space))\n",
        "\n",
        "        self.eps = self.config['eps']\n",
        "\n",
        "    def process_state(self, state):\n",
        "        \"\"\"\n",
        "        Process the raw observation. For example, we can use this function to\n",
        "        convert the input state represented by an integer to a one-hot vector.\n",
        "        \"\"\"\n",
        "        return state\n",
        "\n",
        "    def compute_action(self, processed_state, eps=None):\n",
        "        \"\"\"Compute the action given the processed state.\"\"\"\n",
        "        raise NotImplementedError(\n",
        "            \"You need to override the Trainer.compute_action() function.\")\n",
        "\n",
        "    def evaluate(self, num_episodes=50, *args, **kwargs):\n",
        "        \"\"\"Use the function you write to evaluate current policy.\n",
        "        Return the mean episode reward of 50 episodes.\"\"\"\n",
        "        if \"MetaDrive\" in self.env_name:\n",
        "            kwargs[\"existing_env\"] = self.env\n",
        "        result, eval_infos = evaluate(self.policy, num_episodes, seed=self.seed,\n",
        "                                      env_name=self.env_name, *args, **kwargs)\n",
        "        return result, eval_infos\n",
        "\n",
        "    def policy(self, raw_state, eps=0.0):\n",
        "        \"\"\"A wrapper function takes raw_state as input and output action.\"\"\"\n",
        "        return self.compute_action(self.process_state(raw_state), eps=eps)\n",
        "\n",
        "    def train(self, iteration=None):\n",
        "        \"\"\"Conduct one iteration of learning.\"\"\"\n",
        "        raise NotImplementedError(\"You need to override the \"\n",
        "                                  \"Trainer.train() function.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4067c392-1693-44ab-9024-5142d4fa7610",
      "metadata": {
        "id": "4067c392-1693-44ab-9024-5142d4fa7610"
      },
      "outputs": [],
      "source": [
        "import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf324d71",
      "metadata": {
        "id": "cf324d71"
      },
      "outputs": [],
      "source": [
        "# Run this cell without modification\n",
        "\n",
        "def run(trainer_cls, config=None, reward_threshold=None):\n",
        "    \"\"\"Run the trainer and report learning progress.\n",
        "    :param trainer_cls: A trainer class\n",
        "    :param config: A dict\n",
        "    :param reward_threshold: the reward threshold to break the training\n",
        "    :return: The trained trainer and a dataframe containing learning progress\n",
        "    \"\"\"\n",
        "    if config is None:\n",
        "        config = {}\n",
        "    trainer = trainer_cls(config)\n",
        "    config = trainer.config\n",
        "    start = now = time.time()\n",
        "    stats = []\n",
        "    total_steps = 0\n",
        "    reward = 0.0\n",
        "\n",
        "    try:\n",
        "        pbar = tqdm.trange(config['max_iteration'] + 1, desc=\"Training\")\n",
        "        for i in pbar:\n",
        "            stat = trainer.train(iteration=i)\n",
        "            stat = stat or {}\n",
        "            stats.append(stat)\n",
        "            if \"episode_len\" in stat:\n",
        "                total_steps += stat[\"episode_len\"]\n",
        "            if i % config['evaluate_interval'] == 0 or \\\n",
        "                    i == config[\"max_iteration\"]:\n",
        "                reward, _ = trainer.evaluate(\n",
        "                    config.get(\"evaluate_num_episodes\", 50),\n",
        "                    max_episode_length=config.get(\"max_episode_length\", 1000)\n",
        "                )\n",
        "                now = time.time()\n",
        "                pbar.set_postfix({'ep_reward': reward})\n",
        "            if reward_threshold is not None and reward > reward_threshold:\n",
        "                logger.info(\"Iter {}, episodic return {:.3f} is \"\n",
        "                            \"greater than reward threshold {}. Congratulation! Now we \"\n",
        "                            \"exit the training process.\".format(i, reward, reward_threshold))\n",
        "                break\n",
        "    except Exception as e:\n",
        "        print(\"Error happens during training: \")\n",
        "        raise e\n",
        "    finally:\n",
        "        if hasattr(trainer.env, \"close\"):\n",
        "            trainer.env.close()\n",
        "            print(\"Environment is closed.\")\n",
        "\n",
        "    return trainer, stats\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "64a565ab",
      "metadata": {
        "id": "64a565ab"
      },
      "source": [
        "## Section 2: Q-Learning\n",
        "(20/100 points)\n",
        "\n",
        "Q-learning is an off-policy algorithm who differs from SARSA in the TD error.\n",
        "\n",
        "Unlike getting the TD error by running policy to get `next_act` $a'$ and compute:\n",
        "\n",
        "$r + \\gamma Q(s', a') - Q(s, a)$\n",
        "\n",
        "as in SARSA, in Q-learning we compute the TD error via:\n",
        "\n",
        "$r + \\gamma \\max_{a'} Q(s', a') - Q(s, a)$.\n",
        "\n",
        "The reason we call it \"off-policy\" is that the next-Q value is not computed against the \"behavior policy\", instead, it is the next Q value of a \"hypothetical policy\" that always takes the best action given current Q values."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "188997dd",
      "metadata": {
        "id": "188997dd"
      },
      "source": [
        "### Section 2.1: Building Q Learning Trainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a2ec18b",
      "metadata": {
        "id": "6a2ec18b"
      },
      "outputs": [],
      "source": [
        "# Solve the TODOs and remove `pass`\n",
        "\n",
        "# Managing configurations of your experiments is important for your research.\n",
        "Q_LEARNING_TRAINER_CONFIG = merge_config(dict(\n",
        "    eps=0.3,\n",
        "), DEFAULT_CONFIG)\n",
        "\n",
        "\n",
        "class QLearningTrainer(AbstractTrainer):\n",
        "    def __init__(self, config=None):\n",
        "        config = merge_config(config, Q_LEARNING_TRAINER_CONFIG)\n",
        "        super(QLearningTrainer, self).__init__(config=config)\n",
        "        self.gamma = self.config[\"gamma\"]\n",
        "        self.eps = self.config[\"eps\"]\n",
        "        self.max_episode_length = self.config[\"max_episode_length\"]\n",
        "        self.learning_rate = self.config[\"learning_rate\"]\n",
        "\n",
        "        # build the Q table\n",
        "        self.table = np.zeros((self.obs_dim, self.act_dim))\n",
        "\n",
        "    def compute_action(self, obs, eps=None):\n",
        "        \"\"\"Implement epsilon-greedy policy\n",
        "\n",
        "        It is a function that take an integer (state / observation)\n",
        "        as input and return an interger (action).\n",
        "        \"\"\"\n",
        "        if eps is None:\n",
        "            eps = self.eps\n",
        "\n",
        "        # TODO: You need to implement the epsilon-greedy policy here.\n",
        "        # That is, with probability eps, you will choose a (uniformly) random action\n",
        "        # in the action space. With probability 1-eps, you will choose the argmax\n",
        "        # action that maximizes the Q values.\n",
        "        # The Q values is stored in self.table.\n",
        "        if np.random.random() < eps:\n",
        "            action = self.env.action_space.sample()\n",
        "        else:\n",
        "            action = np.argmax(self.table[obs])\n",
        "\n",
        "        return action\n",
        "\n",
        "    def train(self, iteration=None):\n",
        "        \"\"\"Do one iteration of training.\"\"\"\n",
        "        obs, info = self.env.reset()\n",
        "        for t in range(self.max_episode_length):\n",
        "            act = self.compute_action(obs)\n",
        "\n",
        "            next_obs, reward, terminated, truncated, info = self.env.step(act)\n",
        "            done = terminated or truncated\n",
        "\n",
        "            # TODO: compute the TD error.\n",
        "            # [Hint] You will use reward `reward`, current observation `obs`,\n",
        "            # next observation `next_obs`, current action `act`, and Q value\n",
        "            # table `self.table`, and gamma `self.gamma`.\n",
        "\n",
        "            # Q(s,a) <-- Q(s,a) + alpha * (r + gamma * max_a' Q(s',a') - Q(s,a))\n",
        "            best_next_value = np.max(self.table[next_obs])\n",
        "            target = reward + self.gamma * best_next_value * (1 - float(done))\n",
        "            td_error = target - self.table[obs][act]\n",
        "\n",
        "            # TODO: compute the new (updated) Q value.\n",
        "            # [Hint] Use the computed TD error, self.learning_rate and Q value.\n",
        "            # This is actually a step of gradient descent.\n",
        "            new_value = self.table[obs][act] + self.learning_rate * td_error\n",
        "\n",
        "            self.table[obs][act] = new_value\n",
        "            obs = next_obs\n",
        "            if done:\n",
        "                break"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b2f6c0f2",
      "metadata": {
        "id": "b2f6c0f2"
      },
      "source": [
        "### Section 2.2: Use Q Learning to train agent in FrozenLake"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "61586e08",
      "metadata": {
        "id": "61586e08",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70eed4fa-1cfb-4ca5-fdd5-a10c682623f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  85%|████████▌ | 4251/5001 [00:18<00:02, 266.39it/s, ep_reward=1]INFO:root:Iter 4300, episodic return 1.000 is greater than reward threshold 0.99. Congratulation! Now we exit the training process.\n",
            "Training:  86%|████████▌ | 4300/5001 [00:18<00:02, 236.80it/s, ep_reward=1]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Environment is closed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Run this cell without modification\n",
        "\n",
        "q_learning_trainer, _ = run(\n",
        "    trainer_cls=QLearningTrainer,\n",
        "    config=dict(\n",
        "        max_iteration=5000,\n",
        "        evaluate_interval=50,\n",
        "        evaluate_num_episodes=50,\n",
        "        env_name='FrozenLakeNotSlippery-v1'\n",
        "    ),\n",
        "    reward_threshold=0.99\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9fe03c52",
      "metadata": {
        "id": "9fe03c52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "1109ac55-c3e2-48ff-bc72-c95923d6f15b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table class=\"show_videos\" style=\"border-spacing:0px;\"><tr><td style=\"padding:1px;\"><video controls width=\"256\" height=\"256\" style=\"object-fit:cover;\" loop autoplay muted>\n",
              "      <source src=\"data:video/mp4;base64,AAAAIGZ0eXBpc29tAAACAGlzb21pc28yYXZjMW1wNDEAAAAIZnJlZQAAY2VtZGF0AAACfgYF//963EXpvebZSLeWLNgg2SPu73gyNjQgLSBjb3JlIDE2MyByMzA2MCA1ZGI2YWE2IC0gSC4yNjQvTVBFRy00IEFWQyBjb2RlYyAtIENvcHlsZWZ0IDIwMDMtMjAyMSAtIGh0dHA6Ly93d3cudmlkZW9sYW4ub3JnL3gyNjQuaHRtbCAtIG9wdGlvbnM6IGNhYmFjPTEgcmVmPTMgZGVibG9jaz0xOjA6MCBhbmFseXNlPTB4MzoweDExMyBtZT1oZXggc3VibWU9NyBwc3k9MSBwc3lfcmQ9MS4wMDowLjAwIG1peGVkX3JlZj0xIG1lX3JhbmdlPTE2IGNocm9tYV9tZT0xIHRyZWxsaXM9MSA4eDhkY3Q9MSBjcW09MCBkZWFkem9uZT0yMSwxMSBmYXN0X3Bza2lwPTEgY2hyb21hX3FwX29mZnNldD0tMiB0aHJlYWRzPTMgbG9va2FoZWFkX3RocmVhZHM9MSBzbGljZWRfdGhyZWFkcz0wIG5yPTAgZGVjaW1hdGU9MSBpbnRlcmxhY2VkPTAgYmx1cmF5X2NvbXBhdD0wIGNvbnN0cmFpbmVkX2ludHJhPTAgYmZyYW1lcz0zIGJfcHlyYW1pZD0yIGJfYWRhcHQ9MSBiX2JpYXM9MCBkaXJlY3Q9MSB3ZWlnaHRiPTEgb3Blbl9nb3A9MCB3ZWlnaHRwPTIga2V5aW50PTI1MCBrZXlpbnRfbWluPTIgc2NlbmVjdXQ9NDAgaW50cmFfcmVmcmVzaD0wIHJjPWNxcCBtYnRyZWU9MCBxcD0yMCBpcF9yYXRpbz0xLjQwIHBiX3JhdGlvPTEuMzAgYXE9MACAAABUtWWIhAD/jUhP3qMKCjU+jrbm0i41b29xpZFXITp2qOFS2Dv96IJrOmgMIZrFowuzh/P6lmNlFdlsev2hDoLu18rwpcyRsY723V007L9aKZqhJLX5tz6sDkp7Lr2bk0ZN9r1ET36LlqtCUcqJYvHK7nmFxJtCTsXDsDIptslcoiyJFo5jtNu6Jd/fSqzsvN1yuJJqfkEo5Fau4RXmjbEtUCCzSeTHQC66QUaUk3USssUv7Tkwa+gHSnnxFLqjQc+0+KyGxgRFPsKjki+/VAAY1ZrY2/35cpHUBZYdyLdY37bScZ96gjcIuvXyLUvCd2n1EOy5gO/SxschpMwkzffBcwiq1yPsoAUE95AJocR1JYz0bXpPRSEmFlIxv/8tZm5pMnXSk1ntFjHxL04eOagccT5rNC31asI7bazAVREmLI6WCIhhitzHnth0vvqglwNYF8cLlwl7nTGQgMg81dMWOibxnCE2czWqhhQ6+ZIqehSWoZW3rfuLbQHN9lwi/CBYE3IUYveuRn9pc5eiyVAGZcHIjoHffd06DCV/Qw815aPD0uwT37sFEy55lrPh0MaKqOZrwAsy4ouOW85HEZ2A5MjmkyQvmPvyzG/wLmhNH1caUjoeb49gRW4FImbVKk6xTCOtTRRywrwL4DA3Kwf0qTKUxYZdz7m0vzJmUP5d0rpgxtnEdBJsEyuR9+ur/PKZHLuRO+0QoQjq1H/eAAhxTEb2AFJjncOYb8K0BSlUXVbEKpoqXsOsWRak230oKbP4TSRGIrcnMllgeiZakRJ65KAxjbdVohKR16AEBY/cWvJdYPIUbpRS+h21kbd9ppjEX7UTon0Ffarza5ttTr+hOcjZDdelQz7P5RvuE7YB+Uj+Nw4cPrN3m418GGCiC3uUDwTQUlTod2qgd6LH+Qk6XKjNRYHXKtRjJXdsahP56kIJMKSPR6S8+PhWsTZWTDqUjelr6CoBzdv+XTNmqzn80YVBRnAwvYbpkPEvrdBQMahuslK6sVwt38PPGB0UJLDt/va1jdsv7aG3PzVJJLgpGwNVvRr+eH23MKFYNVAprVYucCBdqUNAUgpBPWZKxOiN0mv2hPA3dfexhVr//YE4m5z9p/UdRoQCHDUOX5tx7rz4x1mb4W8zkMqyYdC+XT9xK97bi5BhX7Gezkx9nb/cUIizU4cFwDjAfantwaGi4/CdSrVeqqgOPihP6tu16NX6GoQhnaixZL1NUbhUMfAWAnEiCeSk9eMht50BeMzIpXJqyW+1cO/5IT/CCbuKJ8YP5KWYyERkDppqZvqE7g1ILpjvebJSGgMdfCJbn9iDaJ2z8BMNhfHwAaXQgi/qtm+DIH+NzsUvo7aQynESgSgN21JGnr2c0A79DQ4V/95OfuJqORUBV3vtvfv+SJXTtvK91vCuXLMjno/a1TN7aSFG5VVUmj0UlBK8lBYmuvqXQaqFh+AZKAWmz3ZoOxM7KgQhZzdpsTlV/E8x8NYf4ME/I3MG3NqVxKF7Y64qJ4Nn9DbUsEsPOtBL+AidWaol/kKT2/3kYNQoQ8K32xgJHWtEMsMWT5jaDDvEZL7EhCfddt2Kb/jlRSWpqttbrvf1oOIbrllkgdv7xcDcPL79LSKOK5GcQ332nC6Fwy4746tqMJfY+XAbs9GhJDdXvAbiXlDflPB/FD9w0vF0Q4BEfWpNHKWe6OWwG0rpRp/C/AqiNG783yxke2KxNX4yrkLxd7WjupV+n3EHwDvwdPVpeQQYqhIjuT6CswCw/ymbMl9lvl9EHIu3GUNg1kAoM0WnOl9xF+jBWC6Tk8z8RKp0oKj0XkFDw2R/QooDXCg2W7BRQH4RuBarwcmkZR8cEZk0PBaWRa6Ri0y42fXyqvF6jes+iAnbMlW1azbLVke4pSQv9lRYkN1ZU1HFnwLT5oruyLmgfxkjjNT1O8WiYhCrSyEGHbcs2U6pbzn1sBEbhOo43fMZaJ+9jtV8qo3sSxvK1KlmfNpbW95Ef4L5HO+hRQuh/RJ3LcF3Dv5/bY50tkfCilf4LXF+Yst0Wt6zSwNlsvj2cElbTQRDbMSP0srefHhUS3ee8b9vELwNhvWqzr5kznb10NdpzJZh4iD5Pqi6jhB1lMw1zSbEnFzCkPX0/nFcbJIMf4xfS7HT4H/ioqBu07tM3Cv0JIfGC+CGUCtGPeJcS9Evct6ZHiFCfVCpwfIXL/QwtSzVKnFEalM5qYI3gkYygKpfdPZolzPMhIDV6badR5bI2CI6d7nsHip9ktZhImPE5Nn3FfFMi0cC5JDGJgMykwA1SgB/ymlxBxHJH+sx/gJPEBpbLio+t+G3meqTpbf0iluTlY6Oyx5S3GrSGEKwUo6s2dCgwey/wYyR7epXMyQNH+QSvelg2/uySiYCx3ygw8vKSJkvJXe9XRZt+bllt/PB4zILKJXXyXWTDjK/XuLh+bRQdCDBnrgQrOWzLIoBE3ee8br7e237ndlvuAYavkUgC2bNim8g0hEbCAdzxQ+GHm0EZbrzDVYLitVXGVNirVFHRS7ZJQ0UNQ3v6TU9yDKcxnNP8DuvRvJemK49jwvSNNB0rd2FX5gYwv2nyAzztvucakTRMPaFBGZk4apBAFtzrZbmJgyIv8yEnmqZPC32FhbR4Jfv52vOUx7Hm5LKY6z4Ef+4yplh2s09WRhL3SB9pIWbOYv1/t825aYMeOfL9UIx0+3xCR0L/nxOAKHKxyHq6LVltAb5SQbuh/Bl+Hj6sAUHUXOmTGsWkMdGuJR3YteEFx7t6Uu7Cf+0Q7BNVuThXsV01K3ouPuT/JavMP+5uehHGQOvEn0fWd9FuUDl8EtmFYTmDik22KiDsqW/B8945+gvh8y2NUBGOS4KJYXuuEMAsXtENEaCYbHg/frGpyroYfP+2UnMfnDNs7GF6MRqKvX/OWa/yranWFiAh5ZjOaf+GxoTM23mQeOfZBvElBqxXsykGmVgFWf7B9td+0iol6qPY5Co3fdOon9FSGwhQortEN67EyEnmqZPDx/762jKfR4+rk7kony+69DQYqLMB7REB5iGoI1kgNwjcllcDfHIyyl8ExHsYh6a4Pzk/7W3TRFHVcXvhNhcnx4j+Afo7+SEv2AIETeQDI2JLkqqCI38gmVqLYhdk8YMc0xa9r40hUDvCf+TiHYSZHJUtkYTDNHfOwEMqp8CtZtABXp3CekQLE7AO5u41RVWO8vZXsUbM+y/YZYl3Z2H/QssP1GY9LUDknu3fc2s5HoNxFoZBDXipCSGKGx3YKaIhEYe0MCUcpiyfmgr4oB65DixZjpCVVn7T3+TdzTYCz5LxsQOT6uSLsmIXiNU2LtnZSx0xrrOBAfRj8Wpv3Or1qf1qk1P6Z097RMrNrIyrbKlfm3JhOx4MlDDiQ3eQ//gQ+Wemz5s10BBVERS1vB2VL1RLDwPI0g2wiQooZ6Ow9I5RamVQIP9B03BJMuVW1bcdA7pxcDuPeC574rYUOFcW4DG2BkSM4jmHgX4uTR94c3fh1qdaboWvsvCTJdmB+p59m/JYbyqMNXUoHCKjXImLqQTWIWB1USzCZkNhwF10IIuFKVWFrGsShrUHvCfc+0GadvABaSbLhbaKi7L6xFW1aUx7nFCwodACCH/QcSrNs2RwxgPr0PWzOzpy34V58kS7U+Bu4YY/U98Yc7aQmM0enpzy4kG5D5t9mokFFQA22WDJZulT2cNR1o6IxWZgXS6PbhG5rV3F8IFdjAXe4/+O4fPPkY4e8x/rep6vLUxzGgT/2s3Dz2nD5pNl1lzQ5tlJlmUUhAss2x4AmB2A9cO++rjEtOtKwFC5AjqfYDNky3j1dGbBH5wr1gMzurlej1ajJ/3Oce6O4yE/12/w5TOK4k2oujHBcM03KCl2GIv4HwcPIaNj9nx37/nNaB5uksmRG5EiifYSx99r/YK96T6E7kW4mhcx08MKTjTHA2lhCbshXTKH5hnfhKICUW3VObBVvXlQQsj5Tm4uA2atq83SWHsuIyZFwOE3wa/tHhiP3iXLHZ15K56/BUrELvIVu+lTaaN2JPG62OeEGCeZseAjfddSqdPv/47h8pjv07GICSGAl7sH17nRFwqPhq1gh+QTAT2wsymD/SmeP7hwLX8CkyVvBQCBaYsPj4MPQ3IRfWKl9x93JHNXRmwF5aAWfeehjVE3uCPP840oN6UciJD8JGjyp/EQeBBQUCMIP+PdNcm0AgHyUpVvEGgEqOhudbT0tPiQ9/WVPA1eVNFOdQE0780DO4owTFi7nUfo9oH9wJ6JJ4D56kxnaACRmvKF843h0jUB+s/n/ZoUvMreU01JtzKSln8g3Vo00KXBWVaA0tIa/qfQXiG8k9sgU04uVf0Ipj9wOtx/fD0zHUoyJ4H6nNwQp8HNxVVqTPt2VwhroiEqmKxoE2hKaeHND89NdqcpMXLqiTK0Zov+TD+IaoaAdbNaqVIaFKHPipIXQNkia8AZ2/CcSEYwe8XrBCchXCSM2y+Cgn0TeEauYaovdWAWkoGVb4eEz1gRTR9Q+UmgEOWCN+mtCuoBytOIOON9bjiVQN4DG3/q3m17oWhm5sJz/DZgP4WyoeLwZQ3HJfGB9BXETV/UtFPJsHAyjT8ucQVjaxITDqP0Fc13SIcqSH0AwRANG8ON1muOqljNIL2f7lqkfuGz5PqE4ypeDXid6efJXiYfvMq1ciFhmai9xRdJVd3rV65D9TsrSCCB3VbgbR35i74IE8nDGaY4KAvHaJV7kGTNyy7/F5KreHJG1AB9Mi1RQ8+vxE/uIJ/e7z7q15yYZrkUKU8nA1+/XU8LFm2qdUXn8RFfU3Z//c4aFRZUca9DKShdygyUw37lKYNojmIfw8LJT6RCj77aZnoR+fjdC7UDgvIbSTFN+P/7w+V/nQVDn+a+FMgSI8gFcwg3aOOKedXL5mp0C91bqc2JojucucCDzPr4gpkxapCEPoBtffB2rHZPnXNEiycmDh1dxZMBwsCNv7nzrlsMgNwR7VmhGD9A1mr+C2rIY0J6uUxAMtjCV4ZIeOi5PS1mLPPcrSVX7RvtLCO4/hExmQN6mYk1SQeqb4It22mVbtWk+sGL9eXFkIHw48grDHtEC38DY3joyBNFUynUqHADnkFohhlrr/w6dLpRTYiPD/RGW7hMU/qba7Njy5YPhCCbJzcWE4o9lCzk/TlUqB+8qToBaXSuCGLUJGerDAZ6mXM9T1X8+sWx2zlatvmmUR6srjdUrqpexPjSDVxrDD9xvpua9+tPL4yokEsDAJbg4BEGr26O1sSxdhwZaGFmuNFw73LzVpqd1uLizL+WTduKU+bVAbVINW2PE/h+uhprzoO15VGpTKsEyZ/lErN3E8NpTx73illDdknuGGLWMipFZ0TyXnxF7ds/5ou+3nOJYC/h4I09oSCh9VEvCJAsodOfVDGaibuNeCVGgTJD+KA21/ZYx7tszrcrLU57UB7SGI8n64ipKOEDZZSlQ4Ac8iPHrsteEwLZK+vK1uk8QGXwW4ia2u982l5VO9xmLHieP3msIKJ38vlU8iIXcr/gw0ZaZYHSoizDYVENsbKWFUGE2+lQqIU/jdKWgTWmwF75k0XyCmX367AeJjGupqZOJB6DEJADyL0HB+C2OlG7LbgsIrTqX5bmD9cq3/NLn0ZX23dy1retre+FGsvoK7gJ2dAabygbVqybeHYVA4N1nSovElCm1YA5jf4vTRL+0UDG+hB4Z3Eeov6X4hVCvOMWG3E8PDpmHVsgVFjNtCnJEwQgcAw2Ug4mUWN5qCNmjvTBZQx5NkLx1P4Zvhm1dlexgLCIbYQ8Pf/nbo+ukQzLnnn1bNAOLT5HinrN2lvbx6hVhweu0f33j9p1s5gxXPCSpXgYytDSNV3pidhOoRw/zqHOVjZjYikOGodwn6lM/d+wvxC8heU9n90ZXdxMhghdHbRHIeXOp09jZGhIJJ/UcdkLBe4eLgsDUtelPsaOJk8la57o+RvS4nDk5VuI51BFK2lOSvypc6JAFfP07NGHPr4zRSPPhocbyozBokvAO73ienCyFMUSxQVALtsajoILLXW3P5FEpuT83DoSwH9gwAGvJ4KkChaJaYB7oczg46jmacYgG48FEYEm+sTKrZUYm0WPU8SoDHYJDBVciRNP2Y1537/0poBLeNuNPx9LaVolcyh3h3wfqVJWts4rRt53Ui7UYWI+aT1su+4w9sY/GB+VaytnotdnzlKgaBGIV/XpWJ75xM2NCvnN7pHIY+fCmO1KM0Hhb9iiDxuaj3LRRJX1033DGaqZArqGtYnS4nCIzSIvKVS/fzueaS8vIKJNjEuCbyNg7TCMBMslcyHu5DFxQpi+jmjUt0FyYtmJs7j0D/nu0bF0zI7cPU08UoKdkZeKaeoNh40JKYh1p8z8LOlbYAfdFUygmD8Q7zjMoeMEC2VOeMA4wGLBUoyMsnWTWQTgnutdT4dpJV3TLt2DDEbzOsz6EvG7/uL32wAkiJ7trTXeRCJvG2JOQOeO+wcA5pJR3+mi5Wpr5fr8RiFLZYJm92/pYdBkdxdk1wms2Ce+adzw6NELew1Heg+ZJ0MTQxoEO7UwIMyoZWnhm7ncSR1se9Ex+99fTUdxpsWec0tatn8TSlqqX5mc/7FDFL1QV+0AIdvfDQobdVeXjTTEsk8gK6MecXYML/JAc+Wg+xgfZTpXUkTnglAIZUYDBVTLuxjqoylpaZHJbuYrqjvxng2Jww2MMkR5XWEPmJdzYAF9lx5nYn4+8jHefNKd2Y7+6KSMRXSLaaFh8+k1KY91yC3xSRi1C+uN1KT04LpleAg0QJ0Yxwq+ukrjECkMBG3ZiFiYVItJuazFoM1NZfYPecTXgQcoVBgu8+M2LzpcZ7/tM+EPanMGSzsyKc5uHbB5DGcM/FfZoNXfxAmw2xPJrazQ8Q0OvmpMmaV/IujMfkVsO73vq/6xbfdQJebUNGkiLcXuFynvClq9TVZ5/V2LBeJVHee8JiK3VTVrKaFqqRgM+C7+7sHlBd5oYYS2CuWRUBY92mdg3+dHe595IAV8648Gj3pTqkilb9ITQq7VuEozg+i8se2ZhBjgoJvvK907i8SZLYznFAU+s9wrtpFQ2boIhXoY7yZi4ry4O21NpvRSzc8KZRqjho8FZj9HPlF0oiJt4i1GSn7FGyQT9TXSNP5U/hnpRet4CHalifg3pVo0TLbolsyd/9Kf/Rm+PNMMgSgf3vIi2F9bebSB+dXyBVj6QSyS0Spawnq5cSUAEGEBhBTWxDp8wSPiOCq+GjD8uvMPbcE8VkCgZzRovJeTqQhhyQNVR5Mw3KWhzk+hsK0dc17iLZwgLw6HOXlQrVuOEV0TTfPejgQH/TYTcO2ZGmDevbzBPa8XiS/3xuDyv/lDwlzB//jWIKV09NSH98cR8kZypu+3UBfqePaZ7bmxtwsmymU8BCBCSOZomo9B8CCHISEWrnKrmgA4b6AbxCtPxbIKH7/TgdEEzHLzOW7qOoMW2gsiM4uzEnr1NBVvMppjkBOnBzWBB7UxBkNXE219AhEEOMD3aAbYFqSXpNWRG65RlMdDRvyw17Wa28dZmV/jfOI1aKztaRfRcDVa3ypjCQev4G3eC/DV/p9nQ7s9ZA9eWTzcCVW1fR3lO1wCyMdUjHXF6kHilfXqF9b5iqJ9QoRVPvqNfs/nlquUFCBKrRh4hIo3G9ZNu6vFEltM6ZLlK+XFaKXI3yL9mJ9GdeexyhhGb+5kCfX8qEMSJrQtXuBH2XezrWYytmtYq2c7fY8G5do3iGNVARNJGxvYr+OamrRl/5h3b/hpa6Fce00dwIIrQGjJWAEUqF2q2z6fy5AaxrGqhTfEEG60MOV9laEOv70MnOQxgkd2t6GbZnp/omhHeZa0lNCRm53NzajEHVIiIu+wTDCKaHaG2huXZKoclaR228pEyjIAgKKl6FlNSoxwzwDWSPSDth8NSMSUKr8vtPLLdOzLahs2hImbNL6fqBrolMcmn3CFA47T845Cydk/i5f5seoAE6zQqE60q7t5WKzIzXYaLe90NRsWxhoIz0tKqd44mSOg6+AvFvef5rbMLhj59f8tZgpok2Nyy4DBlePQqoKE2Pa132VUnGPZKV5Wnf+h8jnm7d7do+uWig0SINN14TmsbiF8W8LSTxh7BtWiOQbkiLZhQKzMSnCpCR7IJBew4T20SepgOhnvEBPXdsUVt3X5HgmKunF8rG4GNHBj+tgpYRiycciu8kdw1hUkerSNd9nonsiog9XKIkAPvP6I7oT3VLr9GE18qEwhTSw8cEaEkRn5TZd2b8SX416ElYQ+pmVKjFOz2N4eg3aa0OPZTEYD9+eYvrc/ThMx48Fx198v0f3hh8eHvm2Y55lQHKalpNXtG0HXt4lZCLuXg8CKSubA4/cGL2k6ylzAYD+Cj617kDlPZZyvHIPzTsveDKEGStINsHMfCbtewflJUfOZtf/V1A0bnNR5r72DPtNAWo56YwrjwJviFjWnRbnNzJXT+V9aeZdDFi2gnoqso65GI6S0S+ROMMybU0HI6Wgz9HOOX4qRFGgJoVYBXlvsPlHBysVGO8iYM9FcFJ3bjGxv75/gtiTEDhVhuRJ9RbHtdmcWk8oTv2owNbbnuqn0Q+gq1UMJKcXmhIqNQ/IWi7sYRd35oAE4iR0Pi5xeEFLMhVxWryYwWHGYESb2eodKBTMLHoiktitl8u0UVOL8pIYF79hRlr6IUvSaCTjQgiLvXKEzLAyo2rEWB4jRkB5JNXguuwLgPa8GuKQlTnAZfzpXZDBFBU6k4Kgkz+fsoMh2psbgGIi58+Z6Mn2E1+hiqNKng5zB/RAXX5iKdmz1WAoPVWLJIaJwbYcN7w1Kd61al2w3QVLDbebf7oV89nacgf6iwU7s2LLrHNx7K+GbmsI876qK5SbebbAoA2HdTZbqIkyAMwHaD15UOCxgWTuStrv8YFnumNr0lcdyj1Ols/aLpLasBgbM/gyQYcK5sQH8n8zN7UofEnCsRq+rFJ/GroAfyZBIYXQtMJBU5UgDVYSFzaOQXY7XucyrM+/oQw/Aob/xJZxkWdAkQVgQQY2vkfpcrMfO/J/Br59jXarMnBn0q8QqDW8eGUqcKKpa5h3OZ3fUxMMLwCB3Tx/WHwZywfuyD26SPhhKmFQeatuXGuhIJb1xbgyaQ7GxqZl2ZU31YvOUWLu4RqSj2pHwHju8t6x8NtlLzG/aoqJ/jUD3emwMM0lkrG7uCgC3ZcuSSk5bhGqTyH9VfI6r0nwXTPuqF6yrgmulE7il4dsk5NsCs9HoETR8CJxxdP6Agb69L9mbOq7Tm1GJ4Ne8/bGLw6fAu6wN/m3BehGCg1t0FGF9am+UReBrYvylA/PPMrZAPXlqE28nzOeRzdK+TCkDviMFLvef2FqId90jeGkf7bRAtoWFoRjR2gZb+QWLK9i+cPAzazDeFkA0tPu3yvCPcvKXb+5rQad1/p7GO30qWjTod47ThSEcGZJxtv5w/lqAyP4Y399JKTZxRCOVGSZ1A/zsqneGmNy2VeyNJZ+hnGESLZjZe1g52+7Ag5QnVDt6L4VasruAgt9GrfWDH+8QmZgZsz5GpKLOS8VKZFLmZyZIdxibOteSVvW5MtZUdkuoaAA6aL5fUo7jNQRAkouo50MR1qX/+md8pRUH7r8jWBVIZbUVS5ZBq9aMSpS3XAmChuiqQZsyTnlikEJnWLOuHq+MGPdj1J8UTIHthDJlss6eQ0xh5QOee4QRyBT+CXVXVm6dIKWUmlBWojZ0iiH4lp2dSFk6wZsoVkvhccpYxGTtY65pafafJ1wa5lrUmpZUmk6IK4c1EBvHAZZ4Wc7jN8n5dRlkbiykoFVKZQdQ0yX7/Z5s8DHvR57qkj/W+s3qpJtlUwkK/zZ+xEXO956gNFdlwZ87/9O6WqHIb5i7WUrZ0nZ5ilxdVi2LC/YXVPveGpj+KjZFWK+NR0m4m3+6Gmtvr0IH+os+uH7Dl1jm5G2pGbms/h+xV4pBdjMsAIi6QvU0of7SiUOs4aKgZKwVDGZ6rE+nBu40e3cLKoX6jLRcYsbBbxQyVgmi/OK1RAKZBGwdWUiv91S60C/UdX8hQGApnAD+TW8FYMiohMP5cmiQMmJllZWmRfa9zmVheX9CGHty1f9JrOMWjoE+RmdBI6lesAklmPnf1JSfm9DsrPWh+Ck9F4Y9McIMvpe4UVSys3+79B3gAa4pIEDum425KsNrGPG9PxhI+GGiI+WN2nblb61MCXPjFrV9bDj7HzdDJnZAgNtbDNs+zdH5wTDs/bjFLvACrdkNHiOvikug6C6B3l2709l5aFiMwNCwGQzxIv2NMEqu7sHDpJZGBgHox3Q0kUa5P9sr/wJbAXCS8+0LLUXs29KIeOzlovfj0hzRNmsvltdUybNbehdjqwTDZyPZtWODOMN6haunFeY2pWs0rI/eYhJIqn7jqm3rO1W+Ak9LveD7q0pGcFjB+TY5ui3zK0iC7Anf9tP9YU8MOEIY/Toc1shOqGPfTLms14MXw3fOi3adF1q2fZ0cbI8FJmAZZ8IAOH8wDIAccbCac7yhXLLm1/q+h4LVR6REsl7sAg8fUnpNp6Wc4/2+cI6tky/XSdSM77RqR6pz5Hi4uCwM0a2dQswO4f4FeMKzvQ90VNtwGGPfEQFNaMTkg82fUUUFXu+ZjN/aqLIzOFgVZQa26Iz7oUjRoUQlcLjtSHO4Kw+ZeIVriAYbLoFuEuW0QeKAplDGWlAXcMqPAgFwltick4eyvNGPHDSHb4mDTwaA2qbHNzMdKlsZ1/LA0vPMNb7tqWSm/QjXnWI3RHz924Q/1vR6sZecf/40Rg4fdQCGgDF+NAodUbl1nLfAyeSZUGfkl6nPN5Rvz06cQnbv8t8CgdIjCp32QYMCTRnF1auUQg0UTKOnO3qYXxdlXRsiZKp5RD17XXwaFufQTKvtaF2iiNFKEuXwHzoiYvyCInCxssQLz2UP5cYiT4krx8MnXABqzAuy1FfaUGyqJg/SGjwfdaWqT7TmvdBcmWP4DX2+sD4Q++zE2uOKQqsdzeQfOIepYnnTQQwtvBFFfvMoTFAwvqr51+7Hb3Jlv0Jrjs5aVVQzLHBB860CO4X5lWP1s3bPu79+8+Gs6IR5m7p+aO8WuQTWitdK21fOICtgClG/CCVU1kIvLkgpDdewtp9Vs2KzbUfvV/A7YkYwzhSM/ndXTYT8YQF1tzuBT8mVN8yGMhGFus/sBhsgi7BkuoNqdv1BWelwayeQ0H2xyIVU2UBOCDU9QwkL02WtCXLE1vl6X6nyIx9bKMzzFesxRn5AstxItgFYqbX/+ktZg9NHLWqmnAwGCr0cesvaCiplSMexxjXjrnk/QppLhb0IdrGKKiiX69xwDpOGLlFAmi5w4iwdLH1HpV0tm0cVgtIvY9SmJ6yXeAXLa5spHN2sf4ZQe6KNQElI6YZTTcSNqCSV1yrgTR4Cf8iaAv75D+8pVHb0yaxXMhgyUAsqWE5/aMpSozNvoU8nPGzZKTDCZNDtW76WPvlcOuleUDqrH3/hOZlumoV/H4UpjgZMmc3wTVBQd805oVSeOcXMq0axDoLBq+yFEt+yl3nLTql6ecis2Ck/OmuT8MnIg2m3BREcwXSH9/9fOV1NMsGJpYPRTxFeDF8zCVN+tDb280/o57jXuTkAVXIqZjMOW2oct+xLp2A/CbrPl/MONP0Khbmc7/XgyuHeBuvfYPPP9tbY00vdu71pkyeeaHD2fCocUI2S+V3cZqNAL/rinW9gcH4cuBpHotKEyljCMDYzdKa3GVeONFG/Ne9RLakruDNZVfgkXpT1E+1+MlOjnlefvuv4iChLHMkMScdlTde+YLsKBJozkpBja6aoonXbs2Pf6B0kARcRga4yJDiufEG8TEyjtXtOO8TIib7/0xUtbbLoL3jpISgksR79AxgqEVafCvRBfvCQGcgGwcqg0WmLazwNRwcgPLhUtmLT6AQgm8u7/CaVMMQV/NAJCpbZJutBg1gW/plDn0Ft9y95OdzGYsPwPdwox+WAWMVIxdVavr3NZCgCFqAzruUqweqBB+PxJIBvX//94IzdJChURMFeM+JOHFt1rVqThvyY7eMt/HZMsYQsMX4ExqwvwDP2MV1wjpm9OVeRWuuffYu5aVCqPrpex3LbgscVmeLLDo5JVpwF6blntHSt2dOtZxK4fvqQsWGzOojcEalWj+Fhv/0EOpZAQ4dmpkf06wk1BUD6wTJNUYDNlNG2jUMExeXG/Iiq7N0Aun19P3pwDRNyDEtZDuWq0KfBpm9eizaTaxo8jV7Hknj9doxbypFZW0BrxTHzGGa6muuXX3Uhaed/M/k2IBFteF3nTyKO/BzCDwu4RFO+ls2kIh0QKd2NLpneM8e4hJDTDxEEr43a40reTruVYEFSAHZd8D49sQqjVWVnAm9zlSp+1p1bHAFS6jC4AsTa+H8jdeUp7jgVUvRz5GoSoAHMJdYRmR9H5blcCAGVmKNHd1wBLCPKjOckvdjDa74jFJCjEcPKCgINCuR4WwkzSok5EanXkpmcIYFJmZ/MxT0TKCtBmGmyRnDX1qWfrS81f+aQTVvgOi8SYJ6t6VboEW3JlvnbE73DSIOaoeCCyaixa+wODsUl0hYxF3hV3H0wI2RrqXo1zZ8CvhMpvCQFX49vXRtXG4C/RY4dCsO138z/X2ha1dnlpIuBc2T7NYe9I0m+q/mfQQlNhBq+LHazH0kKQ1yDpTomGvi1fTgh02lTsLVqEYrB/yR55nPQpuYlrv7b+Nweaq1oZMw4Kl5vbsNonQI+4i7iLsOUZB+e+LCK6cJjTXI8YydgoiGelDvfilestFwYuaB9nTOH1dMRVpRgxVKzkcQXj03L8sLBHTI9RvJ723/jvv2dhI15AY5tpzuLGjMFyjMwLak1OYnTGJzsN2IVvnH4Y1GRLxM86AEWDGKezhFpqb1DJp8Zt2kdZF3P0nudMGcku1D8GEnMbv6lL+ErmbXE/WUa3Bjjfvv9c5/3IHa9SEuDJYsPsAZgPhJLbo7zWvXUPaGVS6D+1XSAT1CCap3KaXJUw2vYDvomJmndJWw1TsydOuwuiGFvqvKjRP2BaxYotK4gf9zKxbJgFiMxLQAY1wukVKFOIMUlpMFVhB5bHLZLkiAMUZB81FpGfMDeilAhh77s0GNySEAaYNabhbygCqs2flq59zb0ibc3PHrBnw1ya/YowVr9+PMRUMehmAmifxuIQJX9pvNlwFEM+OztjVAV8O6lxRYL+3FU/EYrNz9MQEdcDYpBey1SmvmX2qN/7SKA1UsXKDrP5emhoHA0dJzRemCS9xKym1THmCktEE6C6voxtwEDtWOCusWSjQIyEamlWexs/zfD+bHV9hFs4GTpxgvVes6FXxWu22rqhFkdUaOnD3BNCI+fic33U4o689yTf1CZcvg3jlW18CDZmdxAJ14CBCegfqJPdKYkzb5CGNXJwe31b/GkG8e39AFqupNJn4lwbAbORGN/GQueNAkjO5CDqExUvDc+dKNOaNT+ApAwCEnWgkhF5t723nu09d8Ub2Mi/FKXBgXIkohog1EuLZZPc9ZZJGrBiRsuEem2nuz4KNP3e1Mjs697szUqbZf2Fi0a339MQQ/yUPfQEp8DsDnsMrYQerhBa5IT5liXOAHPDBZpcM3YuHkbrrdvejeIEIrz+kdDqT7v6UMQzVEWmoPgqrDiet9jwXXEEcMiKbKIn53gEE76dbhn6LI3GnESzdGFT1YB9lmV6JLKJhHQCung6ywBG7vSTWoZKrBtlhteCbPhqWgf44HQFrItFk3s86XHxjorG6r2/dadbVbyUkxu1JjjXZa7bJ4rtENoJ+v4NUNCuODfHJE4rrHMnMWNZnYIxN1ABNm+iXDr7eIztZZDDW8XSRmuWrrRuKYi9fWvz0PmfMuFQ9AfLoAR/90GQILRpdzUjZsdefpOFAHED1Ro0ySb8ZMH/YCLT11AuT/7c4ySZuFmwsWphJwht6UI3tpRbNjzgkgvxjBSlkXDdIQmX9jNE4zQbuzIX81gmxbdtz6xWQrpkLNKZODrKqBk4b7FVtzuPC4OlpASc+DSYBE9CbMKae6LP92krW61F005xuqlP+5Pi0Fz0Jrkucn9CdIDOzAZYbwLpxwwfhLA4Gswo2QzD4CK5EHvO3Ft29kFSbucgzuR4Ar9aXn4pmwB70whvctd9cRiRt/JP2bh9bAtku5EQSgPcmGYqGw2QM33uSdmgy0w4hV+TGtFfgqPO92rW0YgtMkPOgVLGZRN0zgntRbkBFtoSrpPYvYHzpIf52VlN+gI64GxkDP2BZrU2BLcO1LJv2HVbyaBGMLY5RrHQ2xNGwdvxqOZ1NWbB7vODg4+9PaRKCmSu+epvBMW4aaRGD3+6VndmMXLlB4nPio3KRTrLz2v9CM30lLWSiKRMWNHZJC/kqFQaER8/FbfupxR157kUHeEy5fBvMMWr8sOETPEAnXgIE1pwo0E90poSdnQqo1cndhG2zigSWp34ghkTm78Jb38oNpRp0YoMGdH2zjdMetW3aWDga5yHgHNZbyRvPPGpHM205KNd6wob1DH68UJCCg9sbQYBXliNvBgdXxISmtv+YZVM9nhIyAPaZTEfVNLeJbsaiuLbDZBD6fspvk0DJYV6P1N+oFh2WKc+oJ5z/na/f+ARUXdc12iiJ4IHAPJx1xeNFQZL/mWZalfvNyZNU+pReZ1QkxeCxn3sVQUwsoa06NMJMGPbIPFlqHdq2p9wi36Grq4qCQLYopmBMtuh8eMP+VabxUQFqtwGGYs61UsFCAs477qVEvzlqXreePX/U9WEGDXhM/92nMJ2GQVhErC+dHEIlnROYdVf6jRF1uKXJfHkHVyzjx/T34WudHbwgTUsQAI+CFo4x701Te0oQ9M6nAi9jkwpY/m4VRar61kDDn2xQbFZjgY4rnQ6QUYtEa3H8eyInJPKQ5Y0Lv1bybh+VSXlJsOAPTcsChAcwkbBuMIRCXnrQligy86pP8HTQ/oj/AmV3pLuKT7cd6QpFE1uGf97Qg0uHSCmiIzEffc52bn5xQrlobclwMpAT/qnfDgiJHPxrtlLw8surmw85wlDi1JvtAXyXton6Gibe+6n4a/1alM07+2xsomW3QjhM6m2TdvEc17mJLyr+URkgGskFWw3ACKlILwsC1+IXJViwAj3Lh3TEcZLgm3TzXMV37bblQWraX9Dl3oFTqE6MwrKM4/ER3AB0G0cMOW9TqiXHki1bNEteubQoWgMCBwGpd0n4Pm/hxq1SLgd0ML1xTtcsHFjgUJRrDFa9pBII8v1MP5dqLKc/In54qA5hsfaVT9MvyL7Mbx82lfw4CmAZrLk5/mnP84lLp9EYiGBsjmPDrKW+q0huPP7Dr3UH1bP8h+C6OYC20wwKHWedpACsyh81NQTMpjKWkXnHf49U7cS9D/G1aMHZaxC73zVniWOYwKmOg93BroX3jfLKf4dyYu6CEvYPOXaJlt0JEmiW3Ju3idZcdbv2jEBa8lClmxNsNwAipZrOp4NjdvyVcN8JG6+PlApLmN4ZvFLZhUzb7j4QJ/VwPVHlrRDcUq1yhB8o0i8UBdnotfcbDXUpVaMNlf28K++iuLA9gW1wr1JZYJI64qTaQg+L5A3GBNVLS1AbEhgE1sxXr//2CwUljnfvMYM2Vdd0PLmxUHzRle4jO1cXPe6MNdPcuR0KRP6Wo70kjbXGFasPMSG5mTxkhEUkgABpNmt9gmp2OTARXW6zwnES/eyT6/F6zq6Yv6l4bkH6RQfD5pbn76D4+LNirRh5u4HrQa5KdQSLDbVr1Xkg4MJQbh/yVpi68YuL1TSypUp+FsReDM0Sw5fuWiDxW/1uIIc5rEjPFsHsoYiBYpCSSEM2k2pHb5LYhlYAG06jFrAb62SPIart2vn2fc0ZbyrqPi2LcHxnlpECA3Ta05vp0pmaZBHFE/UyPXlP+f8VZfJ9v75OuQdSBNomgXEJjg7qaxZi1eiERS+ENrN8QRuVdUqdu/y1pGofFGN7lHg4M4yEPgZ31NM7CLONDE2AEqpficQp3wb2ltpiYmQleq9DpkBldb8NJlB4Ujn/jQQL8sGfGQ3q+G+V7xu0B+VVmxLo0KPlG8ts8g7qj1UeYHc0oQ5b0S5DjpjlygvFQjyZy2VfVgtixJrDJcxVDTU3ikHyHW1l0JZxtqHP2FIVrersiX91kC9pXadvcakPd44AfJpTN8Y1vwPpJS8o3lR+1Ey/H6S2jETVYUyhvJjNonJk06E/tG3K9evwAGOyOz3Ad9ioUTtnunHkYgK9UsLrt3Ix854I38ty7EyA4jNJrf42ByslHuytUMaxTlG5IvxSFoftJ2eQ8WUOzvoQEKO3A+ayScf8cChLptHRz0ja8beNzvrS+d5i6/j/UmqxPalb8LKMIRr6c2yJykfZugwZfxXXKKGdt5hwB4x10G6HIvSOnhoMw9QQKDC4b16Cit4m1xOPUV132yi2JpNdSvJMb1ylfsszTh91+M+EYky01jZQaQKWSTrGZu94Ftxy3vdRVOjRkEu/ZR8vlXomHa+4j+FkmcuQkX8X3FxRUlqw/aYdp2KKXbHgvWod1CN2cjMjFDe8+aZ1EOixMZtvZl1RfaWe0wV46Ho3TfKTcePRm6z14fEQo7AWNplwYmlD3xAJ/+GBekr8Dri1aZwbjWwNBpm02eGhv5z0/BXH9gZ3qo2IJnu3US7eA76W740mVw5APfIZCu/+jEjbxpbfXQbQCvQaMYqqHMTvlf/YanXiXO/6RE32h2bM/xbf+PwrArnJhA4XBGqgB/b+3KysVZfM1iBOrAKP5KKZG7q1eOl+BE3UlHFTALX0M8vnfyHDONFweEk5MSgj/DURDf7r969StHxZY6460f/jE2PSUKWKf2t6thASdXPyg0HnoBaoP1vwNFZlAOhSdzYmz+0gpmTTfvWmqs7+oByPUzEpCF61DuoQdNMGFFjgZUHyCuBQMsOl0QVGUCtiBvI4a25MHoYHGkL4S27bzu4ShtgfqWceu/hEoe+IBPQAs900iVad0pJXBoTLsoP4NhwIFn9/WKXC5c6/Q/jLsYm9zPS0UmKrkhYFX+m7fEmPLPNJUXOOAXEH625XACJ4lGBl0R6tmZuR8gyNKlgyWs6Bh3kLXI2uBj/zAgcvcCJfcBhdRSFrRHYTC0vFwdfgvbyXVJNUA0Zmk+gZRBCn8fJ7sjv9KDI26AZD8eAvnDnq3nfqCjUQ/hPlfoY6RgusYIh52q1ZC5TZcr5oByx0ymryJpRJukuHafGu8vwX8qo5geDOVuIQvCHEHE2xNOiZigyuNo8Vo+lJJbhA86a34Fx9qFyCmO0COwdlsUAnffaf27BH/JWQUisdEDoj4qwXlcep5bUM2LOni1AoEQHveKOknDEemOIOo6HxetkZOD3HtWV4JLF249cgjBduTCvqmEsDU3r+8lDqxXpxPJxR8BG04VNaEmxCXYPNQZIdXzPFHHt4wOA8wxEnTrS4H1Yu2trYTNBeSU8wMsAzULIBg9Xle093CauAs21J2REW6lgXfnsqiJ5z5Rd6gaO0Z0dytSIISYTQF190HM4ByyiJZ3WUOBPCC12XXOZS8QkwvHKkD06AC7waH7oRFEDZMgf6ipvT7FotPyDTxIXGbmskvGmE8WrnQ5jZsdEDFLoLc/IahIjeRIo2mXdKwEqKEJhIZQVlq2RSnkz/medONm4mU71VhLj+3Wth5rmxAfyfzM3tSk1nPkJf5yfaD3WnAD+S5xDC6FphIFlQyAGqwT/ug6Wr32vc5lTGuLAjjalTX7hEbDa0dAx87AdhXa9yKDP3K56t9I4JLPIdwEILJuEQwqQ1NDRSKB/QEIOslMTobYRYlzPwCWIj7dsYuz9I/spcPXyrPu8juLVuC40aXuZ8DiV7OShmNViknPGieitTgikOsmWA6O8OV85zJZQQ9NMUL0m1JW7Iu1f3vza6BHSfi8qGRbLk4QaqK8r32ogt/QISTLnP9zPUeZl/ber8hrFFTRs/3QEHfYa4+/X5mPvrMgB/2DBznwq5y+l+66EMImY03k/lLovebDJ0dj8OAPnXMFHKumRPyKdeFznGLudC30LzFyc+ZYitHpdHTQ+eEjBzmKduBDsYk3VoCOFO66LQW5GsTye90abOe9r0YxqL3HygwhREqz+qMSaPPBfcPvA+mT1O//r/cbrv8/9xnBNq9jswkyk0Xmd+LDwizlMJm1+k9F+q1EaI/nU4YhdBBABx/5c9iOcdA4qY5gDIuPQjtwYRX+hnVaiFt1vSAdqxb6CHVPqNnOkMbR7Y93qekEt0pVaJXQu01fkczG4uj+51ZNUwscFEwGZ/HPczsTK9gpnz3jjl1/70F3mIC+splNbGRtpC5ZiTkjWaCvIyjONbGZbSnNtq0UNSzYu65gzCcP8vLIWU9vkEnDjKUFtg6F9Z/chtHxbQgygvBMsWx/WxqyHsOzTnBOqbx6FGf7+hxt4bVPbLOgAOZ0P7tcBSPt9SS8VDAw4pktV4xVeIQlxi+649xpgVmGg61W7xxdiJC0PCVslwKc/Ou6R6jt+nF94GEKxbRL52age2u3Hebm/ERHUFuHlvw2r6Kg1ePyV+iVMsx1AB8jQ0xd5H1odZqZpYPmt19BNqk+KiISCzzCqwfOTHTp93wKoMG/R2zwUG8SH307Yr2CmaNtO7FjLkHyylPwMf4ruXdkLMMIe5XuemN0Y6pDkEUOPlu3yYaSn6lmxd1MiriPMxuttEcnhR/aMGBTDWT2gAjEMMlosV78jVl4nPC8LmUOw54iNgA9Udeo5aak1pHedhCvVK69pX0YiWsmENRPjtNePlNaNYaTukAtLxZIL90z8TZ8ti0WRekaovqxfHPqm2li6gBkvHY98LqnLnblu701S6EYZ1BVzQCA3GwzNjModIduLsSJEs6nKKTYNSOO0BHP7xz0+LPYKvC+8N3sR7JinjSDMaOaFDUu/QRTzz48ly3cSI4cmw0he0UfGHEV3RdMKrcxv15J2HNMCSBlFi0NrpmwAfmKA1FBJ0w7PLWx0XKqTrxKQQ/+9LNHnq40RHAD6NgIZq2nFvQN+FtVlgEvj4CMBv6Z+kfHLTG38IIMosJKorH893ZCj/qraEDw3ETh0N6RLW65pesq46yIe+mP7bpSy/3cjuL2j7EmRA6GGpqAE8zGi3MqieA4qg0XeX+6kjZ3qgmS9UpiajxCicT6a0xU3X2186plTxND2WSknTMNepTkFJIWLbCye2pXXPvsVZ7PwmFOIes+6LaPceGdVmjWQdC6S1rhYPZFh4gGVSvyS4WIaJMLH95ay0Vcq9S53CaNzPSogKR1seOnHeyPNlEzgersj21RYs1ygPWmhBiNlT+U+QZhyoJqrvS34wMrJJQBmHApOra/D0Lp/9uOswJNt2jxPiyLxnrLleG8n/iLM0crw3TyWRTsmuuWrnAdOsuPI3V0cIDKuAhKxr/Y4cHcLgTYAkgRLZtIXH/ETvfiyjnNFUTIaML/ASysrvja40reL9wH164pU1cYf3uHqI9kDAXtOxL4bWAXvgywW4ErmGK01cIWgFidZqRQks4zwWeO4Bqt8m8fk0XvPpnYG8CVyGjcVkEqu2EcQni7+4dIj8sUGrnSdRzWtPEuW5Z/EUx8w5RmA8cg2Rilml3vhFLnilQIIRQphyhTjdkfBzE9pjrxX7NUWAfP1n4HtWBrXMP/UulZgoAQNrKPjx8rBJM1e7DS0+hA340EU+vJK58iPcSNn04xh2LJw+fRHNMb4n1SpEsVDxkN/sUUtAOQVcZtJUwh0nx0EupedtEcJj8WxYjPM//UkhCwmpiDnZR0VoOysCSR8tZFdVDtrgrqyXqnoiqrzBxjseSneT86EVKN6bD35Jn+fyTkw+hrWGP+C+0OEXm8CHKQPQMwbCQ6i0xVCAYzXrvx2M31NCJX9GsbcrcFbJjwGG71oBmOFAcBsNBtHa/lbrV+uh19mWA0M4DOr6MEjrRk4ydXR+HQd0WGv4WjF88qqoaPEOzWr99AEFYwCfnj8Fys4Ho28jbIvNdsaJyF1vNfi8ZHmrZ0nputpmQTFCXMhDaO76L0OAHPGLU8BJjCcFJRHoAuo3+Pc9DixITahM1wAvkF3ARiJGd9+Rmb1VR9Kc/MZjUF3VAtgQBcZwkUKds30dpsNhZ0wueObfSvURoijIjVwPt8rDEJKwgKYO9AoQxtQusZHe8hVNsHtY7Bg4ooh/5hdcAZPE2dT93OOqx6TFKXRKxFFzMqDCZTe42+0yBvCvrjtuOflEWIVMUTvEmG4KkZu0fOcDzzAc1cK0IMPT5s89+/2hx4vyqvOCl5N5yMtvoGlgBuBxuQc54A0HaTsi5k6/2MMID+te5gU90QE82QiKQxZG5F6G8B9bfay1goU0H63sZrXGVYAzE/HhTnSXcKwCsyj9gBFzyH4tpFxlULoL0OAHPIMvq/UvsbOFZ7v4t4fzsJR4K7f6yRSm+tB8XLzKP0W+DzlBzt2GHGPMsBqb9kf2U/42y1CvTLZ18RFooxMms2tKerAP1fGJZcUjQI1wgi2D0R80Vaj6PAxpTF3UWukVAoctgxhQ1woyNTBQ2uDO4qcEw7T2OPqUPOYWh9TdRbDo2LNAe93KiohoWt/ZBqltG1/TTWG7ik2RYFZw9GOoGJtH/AffmlIwYfkrc8dgprVMgz1TxPqvLsIFm+RuwqCrsY+KhS1P8JpdWc8+dQ/cYnHyATAMUpXD1Su1A90SY8CUqbLGoUJJgA8tH1JmPABLrYjXmknwUdYkzl5b5TI5ENaHt1cLmFq6szOZnVfVFxCp+kMhZFGjL61qItwvs7XOBYmKWvUGbtxhx8cVQgh8D4DdHeawaIh7Qydl6pUKopcH/RimOHR5qgw9t0QkGZH0oIYuV3ZuD7ao42n+4ZvWFYo9n/MVbPT7srab/uZWLaN4KX3TveR0OaYH5VB22LnJJMFVhB5avKZLlJa4VAY2Ddblhr0wgpMtd9edHPWdnZ0ZH9+Qb8c2/XWAB4d1RPQUD85zTARr2Qs/JuFSfolyTkYpHvmGbUk6cYmpZewqceSRJhhNZLkbIC+m0SzrRYL7Qh6npF0lZjCoCP4DO4BMstjAJPx9qiKosm/YHcZOyWA+p/vDAeEBmWjv4UMCrfO03LrHuIcaQoZy5EoKZMj4onXluHDTSIzNZAGsVt+sD9eEoPE5QGEXvfWvsq+kQKVJVfN1mhtpq4GTFF+G/2X1QaYB8/E077q0Udee428QBQbiOPpNOy+BBEl88Tt4TJbOD4nVWI90pZZzfkIY1cnE4Hi/2yd8nnS/PfxRfSUKQczd5cMjBpJMJHujsxcEQkfHrIO89b4AyfZU7aAMdNW53hpHjERSGXNo6c07x+anQ9MkAIXj8SN1zbuDnhDmz98L14cSgGV3i50OHX8FQ/Lnl/B5gnZayBTK/QAacs8QTKZKkrnZcQbeAROUb84jGWuibxzlEZTdvogq3th1UySMhig/7izOeORY+FdiAjWLOqOYp78KH4TccK885X7t9Qi5B+2IFvahgmd6hvrNbJoQSu2q20NqqhIGbePESq0cTvlKd4qwvV6EBKBKyoG1ZRmpmHIDGkI2LWhAD/5IwprPbPkUQqZst9RfttLU9+cy2nnT6R/q1XHNuKJFPmFmKLp+olfSb9vQw8TM/xCVtrVmjDYZWj8+Ldz2deLzzylLGufTAxMKzg7fjcZGeCCimCG9MNUtMJghmleesr5GCF/jX/H8nkTMwlESFo2tWPXbRJO86t//20KMU8R0mQLJzGu4oFn+GiVCK1C5o9iKQ6NNUvARtxx6OryABu9DQK3QXbLgf6g96TG/c+3efeBYR8yjpmGpfsWX9MIRj5MdpLD2I5uQfkBqYgko8YXPYfD1rPe59gL19zQ48F2XpSu7tCoum3rUxa4qdZwal8J5TRAkCwGq4h02+epx3LmdxbFLVoLvdsUxZvJk//prSVn/MbmpqCUtVcguovRThsr1uU5/bzR8HoPeUXx+AmLiwgXxSg09O6veGJY63Fg5mL2yIRX297pe4bRbR7wU6n08ngYsBSoADWPjzTA2Unkd70YrI3wrenNipZoyUtquocR0l/sR5+fBCig+SAXm2oxmS6Pc5a3yiF7l+vF7uNMFzNXlmqB0Jf/9Tw6hZg5yBtFuozsnel72/NHxPuMY1B6PiYWpgaEWdApEfv2jZwluc0IkouQOzWaK6cQOF6UkySUy1/h+FysjElZyNCUAjVBSOGEs/xnMdvyL7I4i0sXZwtf2k9UZnvny53jVszTzoVdpw1W18kIKElESqa9AG3EhKP5YYT+B3ZjYDJiFCuy4q/RbEuhUHq6Zi4ry9CZFnaLqGic+LlaISOPoJTCSiO4awyDmPgmbf73IeRJWJwkc5KAlB3rfJlOpmw1Mc9DcIT1KpUAHrlOzzR4HUWTdtuD/fN4eqAf2scpbO+dNJsBXOXv0olgHi6Hcq5rLIImL8apxhh4w9BKHr7yYS2CpdNXllrNfyywZwQx8iTMSGhSxk3fwOGoITnMRcHjIn3GMOpYspoTgxpJ5hRSMsQPQnhU9uH3dENTdNfyrOZGHLb7dm7NMk0kDWfNlo7n7lVsHCYt2jU+ixqhPvyltx8WPGXZ+Rsmhvyc9sPo+sTGVTodfeQ55vA9curwUK5wqT3FPSMSHt0ltzvIqLgLNQepD/xo7D5nOD0+5DY+I8+4g4aaKoURcjfsZxGay2Hvmlr5Lh2RPIMK63rNHIV1nhLUYQqwWd/cuMr/xziCOwzOH8l9+Ih5W35U2SMB/gSlrFhvotFq3OPH0Veqk1gOsJlalx15b6hOa6OMq0nLarmYs51iYtNbo2DSzE9B+LHcx5qIekjmYFduK47SjhWJSz87VF0dhXREvM9lPDMKS6OcZgwLbplW8adyKGVrFzJ9AN707B0AvSCsetlEGjyTsrhyOh1/tLQnOIiXdR444h3F+IhnB+fASOz63zBhM7EVVO8QzJ10c529bx0yWenJbo1/BTS2VriYZAdMhUHAA0FLBCWryyiFWjw1/M1T7mphdVWTWQPFsfMpo9NNTbCZmhwYd+XdO2M+oyqRAkVpZgYRsMDJ+0w+pza43LRiA5GIr8f5LHMoDTOdwS4/pT9DDO0/4pVYrJqxswUQ1cIMO+8VIKdnipkSq19KSGVJtmq2uJSQSkcFCZwxHpjiDqOh8XNkj2T9gxH0lij3TQCpIbINbIgt0HECpHhaUi021nqgT0iGTTMj67c2mrxl3QTAmTezf+6wx1jVvTZVxd1N0FHDRqC3pv4EAUM9zOau6elA1w/b+6bQS9VNxuVsJGTCn53pydb82mZ9oePaOQf6Bo767/kCt4Ycwf0QF1+YhUcJHeJxSl+R1JaGZFBha7NqvmCphBVtf0rOGxbxGCz24MjZ9I/1FYr42N6k/INRfbcZuanWHTrfwb7NQ/Vki5KdrTWhg7BWe/2ZMKrr1ZUc0emIinSfYmWlgIGDnvmxuiT27Lq8JLX5PAn4RP/lgCu8xTgNf3HQ3LOkz6jq+8KAv6CYdAbfYQwuhaYSCh393xIGSHHChI5Hz7XucyqTF/Qhh2E4bp4A3dD6OgPoKwIIBeXxjQZ+5XPV/eYfhqbHfK4fwmDEQEgBSxKCVLX2fLJWgS7PM3nFQlPvQCB3PiRF+8LYiS3TYmASPhXOYIILLzXzRMCW6csf/FMSLZyKr7okdrp1S0JfVLQHXbL/0HBVqQBiIXBftBpSHPsEDrq/fgAMcIsj49ENw4UJfyb7oB/YzJYK/WZyI9nJWNSVJN7yXL62e5307PgGyy5klDlXpLBVi6Jo9+e+Dbr9Lho/VTn4Rbq805tVU8GveJM38eoGkjuiEcUy23LcPMLiyTxk8IN3oRZc5iDkLcckg98QCeXwjJpPkZ3cfTf5wwmt1mFXsPAQuN+f7jH5jzUjrKEisgqzFDz/9OFsByVBBAEAf6TJzfSVv6xVkYDX+NbGlsttLO+MQvj/2mjHcarXowhxLai4CPTXo+nzfQLQweO8PEWj94wP1sOjc4Og0mOl9YaMlOq24UoJtZ1NZz/+GjDYoSRPNb3KQKogtfQzyPcAuI6Ql2GfH+bm+QTKCqe/j7r9Gg15gjFRF2PMf+ixs9A6+AoFkSj2CEFFiDe8jioItceDb54WE0oXwAqtuTgw/sEu0xjE3neguY1tcGHYufUjY5qEXwlmxcJhgm9tUmINA6U/CWiEyHVj0ts5cAQts4GyEnLmCDMPoTszWBBxxmHO3ODMOXpISh74gE9MBt2IhoMvh6SSuDASXqzDhEKdX+FG6rQvXxiqyYaGSoh4167B7yc9mjwHj0uXwyCVqpfE3Z+CAHGIvPz2zoerfodjsLT1XPWhpKwjp0wx+xWUa5yrMqT6+dsyhIrdNePhibp+tLpAKSez0yAZjiyLJZtebKb6KXf0emq77xyRJ0mP8MJHf5s2P8+N1cVzxtcYs2y+QTIsTxTKqhKbujLedSClT6ACzDY8nmZ3aO/9qFCgJ7JwIx4ziZRWU8DY6S+FPbMP0/UJD0sLaHgx9EmMTd/18XfSehsq3jK7+FAhG0OCU2zOAezaOJfLZXu4sYVmY3/SZso2v7BXt6cdHAPKMAxjKdhuNFrdaU4BGr0TSIhU2xUTfa0tgGNcD3RkWLnW8fWmERYjxDRwYtRceV5Beasjz/jD7Y+9EvjHfyaqL3OZSHVy1sJteXpm8exSHtgdEI/bKey+yRcJrztSF+B+jpOUfMhTFN1kdjOJZIL10TttNRuNqjOzCu5yAAZomPknIfyxPxBqWTwjVPRKnVZa0/lmrX5tevGlzaciVu2PoVkLdaRHHAqK+4RLSJyS+XdB+6vdKDmW4FBzvWHsdQVCDTQnWqXJvOjVB1Mw/szo94uRVJGdw+Np5wA7zUo4wk/SXKR/TPvjrX3eF+plRZFvytRSESackeGhRzagrYx44CWCVlaISF8PGfxukrYOpH3PIzR7pFdicTGD2PzKbOfNAlH4Yybd721cpRCBLfsDQvmiN6sG1m9o3Fy9IcS1SwDTLrhQdSptOUJ3YB8/YK+a046zlrY0hEgwAq6NVksFAexBoLGoDUJI07OPLjWBAveW43lg+Wpr4g/+HpcU5jiTqc6loX6bp3s68X6/pPdv1PHZVzKHd5mpG7U/g5cuT3M8r1BlCW/Q4htk/yGpPXb382y7Z2hmc2HT4EVjiIolShILPfxmMZYdFuwSWu0Sbtk31XRzU7CQ8OPUHm0YacalX7wKNNQJiEE3PZ8A1SUlQvACNo//xh4KFmrnQ/Uy5DI0+Y9PJ3Vfma/i7t2PlBTVMrF6Nl8+DoIaU0YE1/IeWfJblPR4A0ak+F81q2Xk6q3FHX2sVS6RKgxH4zGDgL6dIdLafDOdwZk8LXjeTiRg7/Z00F6odwp8FqSUvDpUjJecdWudEI51G+w9veLYF7F8AGlbdAj/hPZSjfhBKqayETc5gUhOT6JdrdUt0UDC06J3o8Ek5O2GYYPTKtD36yp4NWeB4YDBvCvvpai0IwB67zmLMkcvrMmaCqGPSEu/8dK+c2OHKT9kND7RzPX0nSpbI1RZxJUV4oAStVFp+pu8B8xFul/Ix1xYCyTqXT0EFUFT77X/LvBoX+GjUGG27R5sIV+bfcfLEa8n/kr73Ndie3ocK2Xn37y1+A6kko1MnPzOSDHzNtqI5G46LPoH4EJFE6tnbbziqqMybV4I0cInQOFVUKpSMR6Ny/qGAwmY6ZOR23LEkkbiiHgJWZKbxKuXVHxeutehcJjyZt95OciuM59w08slBmv+qWR1RcbfQ7hOeQCxtisZukI0bvpY9m8DPeCbeHn28VW3jvLdM/CCwIc9+1SG6ERUqA6WnNcaFUnjhonVGg/IRBc2L5uvEU7XuNMqoj1mMt8rQUWBTkKvwypkKkIl1PosSwY6hKNPUXTSxca0REEZCiE0SNHu+zmvLWSgp1jpyd01u71IvYs8SY8KcNVyrEqSgZ/sDuLO6OfcDIvlTdP+7SwLM47hFpZycm2/F2ZI6vhgz+qF04hClBwCXoMCjVM9u9yjhheAseSlCwZBZzm1xucPC8J8gGoXf6k7uA1ffnH1mQt3zhAClJapaZs196EsMGNFImiJbdftkIg9k/h7bJS5nXj4WGslvOGyvVCheTJyYT02EhdLh+Lz536nMHR8fsWMJJvRH9dC8fhd6Uv34QJ1bqEbYSv8s2nxtCfxpQ0qeuQt8Oj4eVZc6tYuJmJjkzAZVAq3hkhJV+otm1jejopM76N2fbTuTR8B3GrcBgXVscF6tkoZmHIdq/AvohtbThSukH2PXsPju6svvQ7i9bULnxL3uO+RU1XeS0bQxA5VENhkaMqsEdWz5ksTR3LYlfqtJc+FxGWd59AcEBASsr9kY/hUwju5bfHH4y+oXtjXstMtPRSQA2oIDpwtIKBOsuQtqVHdPER6IaLiRHWJTv43IW5ggI2ZAgHkutCbZSQMfSEYv1v/3mEmBk5jlskRWhbrQ7f5lKdLXGjeheML+McXiFxBstoDyJmN4yweBYj7L4PPmNLKtTZ8+qFcuUa0iOFL8HxwEqHRO0t7AuiuSDIN5AiudwVkZYzATLx0JYHcb3dBQEOeVHF1jV3/ArMAD33/zz2sZxHZsL3+Fn1dahM42WCPodQjT8Zj/sRnxKohXc57KwWGyZdtxL2cN3eidAl6KZ1mJVP/C290TpTplgsla5/WeVACCHYiwKgzIfzMlZTzPDAeVqwa4/MmjGMqF+9WAEguR20e9O/79uv4KRGNXwHvsEtcH2xiZtq/9GHTp3kdF3iNGy2Q0oqmPTVrbZ0W6XG75wRkoTAflfC27IA9U+VEkOMqZL6Va620clvvtlEfg109tYdg8YRYuzDBjofyFpdoIR0p7CL+SKoW1CCztMT5jl+ydWG6tgDwKweqWZZ9qQ4tNWShc+Ky2za2Kubc6XOMaj3VDrZhyNhOag0DiGCH5mfzL62S9pEXYuAme/PKRzkCiHt859xKO7lc0ZLIhWfpLaMfxS+0CLZwVEYA9Z1rt3yKm3adPNMnt9LPpTRcM33PZmIzkaSZRL9ltL283YoDSf7aaIui3nKhhl5Ex6bBubBx1gKovf9iMQ6Tr3DAyGHRLDHvOCC/sjc6IkttD4eNvNzdc6U+CJoS7+uUxG6Poxlxc3pHdDCONGPliqnzbbIR9OYI/9YNSQLUuuOiKnBZ2qRPyIQW+SYxNhK6Z2GviMtKT+tsHPfWp2r+il7hQgFpaOOTPxwlWI750clZaELDDUGF/ioGZlHzdLeZNY/EeLON7dGzGejwZ7jnF3Y4/cAzClXFDtpmP6pNac57w/+Ygx+FWmXysgZras/q5GBcBVqUwVWEJ2cXdrVCn++R/Fd2tTiTYEKw+QBC+7SarDnPTtm3SSgZCSp0Obm7lMTa4Iei62R4v4QR3iVLq2E9cFqXwUL/SOBYCJrkTPWhPw7ro0DvDB8NrfGQDPPRzrpgSi8BN6Qn5qYvbU9sb+rUgHfMroCujQ5gCwhHuwGHa8ICrA6GNgl6roY6Lz3Yw/2wJaACltLy76v1Uyt2nqYZdSA2oB59geBj/RZGKT1cFGASEYxyyPH9lyRn/Ux+9Pdb0OMLUfvLYBGWjgqlBQCzeoiGpiZfxwxR157jsCV2juIzLH5pnYi3oWGMA+QUvR/zEtWI90pgGMyWzUauTajqhwY4n7bOTq/vJuRzyp/WC4rDNamnTfEHTnvMmoJwsYtfg6j9J39x4B7H/FJNbK68UToOtRanJdwRP1/W8hXTqIjqVXvCXhTP5C8kFGYJhVQ85jgo5VVUglRDSvmYZsAFhvLCWLT0DLpWd5MztOxj5Wtq4R/4Spcw7GBMJ2m+rLUvEf8ZhanaAL6BPFY2gvQ4AdnrDYofg8S2gu2XPlQPE+IEzliNygEddrt6SoZ0Q7Cl+IS2M5O6zUD5toYhaYt1z2xbRgycKdQcOQbKonxdwPW8WcQFynqv5qtHelhp3wcHf2pmuDnuc7rMBnu+JTxlkkLn57qouxGMxoE9GsZfjogn6sjovD2IeTfOCPDxIQa4jp6TdbgWLrQaEccJPG5SY6rwdYUxcHP5ZmMQxbAkgll3gPYsYQpxHyXnYeHcvDhhvmdzktR+kbG/k8nlirn9zskSiSt6bw72KmPbyHbwT1tF3DoMWwEiSJohbolABTngUkrnriipBzQhAmtpuuUvcgcmowuhnUP8DRkwRMPlMR9kZfn0cASbEOJdGtlpYp73P+xCyghCG5z2Z2UBwdGTc60tI8Jza8oYZpuxoT/3ECc8iwHrsb9zhkdwLrk3N8a5PpDRftj2nwm39yjo0P/hYrfKnjiVQQY1EVTzw8ide5d1s9+gze11J0ZPWaLsxMx6iZP/LcDGI99Cs5gaQxwZOehsUCYlhgUvXdiD9gcLnnQuhB5fTmoBGM3vAm9hBawy8K5Sl0tMoin/L9TqSpsKrKRT2UqTWC49Kdj0zBYdjJ207yjA0GnglVm1kchwxZLTCF8ld5Qbufwfl45bcNyYHFbIGlFc5wJtC9WqEcTcZ2tLiJMRH2tSA6nHFTI4V3KZqjBLgPEIHqFt/1ZGCd0c0copCEcr+rZGNTI/rzmW2aZRnHecsDRK5DLZfRHjBvMypi7T0oUBJzKTY0AKjIIxRu+dgj4i8CR/6dwgHirgb7DOAploUVrUVQdzzn1HxZiXjM0kOhZV7hpQQK1I72NwCBfLSLTa9qwyKsyZIxGFjVq/riytE4BxQBH+QASvBriQthi/CF4kJ3xydwgYd+DZJa5ncfMqXnjSJ46Pr2glxghQDQKvb36ghuRRC5EH2NPMMCo2aEh80JwwQq2P141X9ZSwWeEUA4q2R278kFnqFv0q4sCD1r2PEAAAMTQZokbH/kQBKCbnmep+Rf8lj8DJfWEcV9wfrWvrTpYl0iyHcZ37+vZJubB+anhlOWJhl4vKZu4egrKCdUDvrl3Ocl70qRKnVPSVdAe2atUqnUNHGg6UNHhCeSs3B7osOTtN0nRROkhOPw4akdhkTmvZ1Cj7918feuuBNXVbXDUyrK5XAjfhCJ5xluwS/BIqylxVh2DOep3uICqHY3B/V738G0wFJ0CYNKSON3RvMHQqyOmiDYVjS4FAgus1/qN5+bFuW+/t05C57PcqL3H/pZF9qhMiJDTMV5Ldjgoj4uL48zKta2ZACZMGt2u4mSkjNegwVuVs9nG2kFRXCLk7B+hq1/6AYMDuxT0Syz7brDgonSl9ezK+RCKv/8nVCiD6cJG9UqQj8PsfqJAZJDoY167thk+gTDwRaYWE193PCUlZe9HkgQsqGiwdYqPdbnWyRvwKJMuAzUTGIPtUifzzTWjgaV1of+h0Wvh7wMLd1DyTe9I6XUxSrsXo27L4evx+t7NjxwEf9F13HarHgs8LcriQllnAcgHiYL/YT8rgTh/+cmJ+6EIceomEjpLml2SZCrDYrF06ffOHzbWPLBkzIEbcFS7QXzmEieqrnOqHvZf06yL1KYsRayb3evJB1RZifXXIjNty7DwMose+fEA5rbRfqQoZL5KuLG+zu91VGtIW9De/4JBJuQFvsZaonKj1ZQNM7NJLS4rhud6AIF+RuAEFYoPlaM/sd0kwonR5qV9lSgD9rVlXkYPH4ARZfuHmI9QbYKy5cCHw9X4weBFIp7Nc09p0nL7b5zGISdnjTeOjEg93BbxAwvEkZi/NwuAmn6L0sryhLOReXMuE50eHjaNCJ5ovEQ1Guwn2wSpdVFFX4HmGgrPKWkycgQodmU8xSiNRtwQlwK27aASspGVS6prTv8y1ivZFQ5XnvfQe7cdXUMpNID7wsvWpdRoY3XbOuhIQCCZPL4f7jUK319/F34cCaSnzYBjkCtkxXNHIRSsvsFwgnbyCbbkG2Qc1wr6L4/ilzw1ccGsDXsqKlmmN9P78joqQAAAgdBnkJ4rwcGpvWIR3GZm4a4Vz//P+BQm4XCq/T5DF1lQmKX4bMUVHQqSEmMHQIXvuWRDsgrgj1mCN852R2c4cLFIyl78gBP3AmBy5L47l0scmHI39qzuX/guEzHg/6BHJ3onhI3RtvtD+xIGBnvovdSMfAnEao4kMOiw6aoFW6twkAD4rbk5IVOxa/eTFuwkAxfd1pOGwvxwTAeAjm/8f+zMM1NqM+UgEFTtc8iuGCaq7CeXMD+6ogtwi/3Y0h1T35kCLndwe3KnObUZV/EK99610fI/oXE1AYWSo4AJj9mYmrJhrcSZCA7wHGbqsdZmHyw+aAio8yY+VqTEiAH8tEfPyEcz1sBbH3/WX7UzZ/YoR2eXLkmFqcQ3dfUomFzJ71S0+PA5Z+GwBS9IOB/WZDQSHU+j0svBs8krYvYbxMd3gKed0XPNYJf7+T9Sv+OrhZ5U6/s0YICG5cYmel1yiNVnPoodKzPrbHjcQylSSkr52s2IU3O+XafZsCjmgr2SE9Tp0Mmjr2T2JWQXaUOfEY4YLIpH10/tf9j8rA0xjaHy9CTT88t7hEHH6RqZH1sMpCqLlTmg4uu9ttKo2B59eJ0Oc+CYbVzjywV1jxBEpybqRKVuo3D/34aIOuaCGf87Jw2GewN6AbvF3H5Pq0GPOpHM/uEw5yP8kGDhTagvHtnyMRKMDIEykEAAAJKAZ5hdEn/CAzFSElMx/xqWVmR1CFvTx3awzeuDEAk8mh/+oR3HByK34QFaFSfCakaq21YmLphXuQqowLiyj8AcLd7ESpKTrx4r1DqSLiXTvPJvceBpBTLZ6CpTB1qv///wXAiqDsi8aibwIMBQCpVlNHHBI0jmcE/n07g6cd2DMcxEAiAwvgAGuHbit6Dj1U5m2rlEdsgx4uXt/yMVGF0VBYHnasXWyn5VpurYofyw8gbV9mnVv99+H7AFm4R11/4e2XAy/A+d2R8/g/aA++Ca200KDD2TP1y/L6erpLomz0tQ6Wa/HBfndtYCMsX+4TEPYZGzIUziFXbzXU2TIG2/NJ4UM1cu4R9hIC5h2qqfRQIvqMPl7QNpu5QBrd3x/3nmCRVC3iOT7GwlwWNhDkfZTI9u/f0pSJQbkXeL1Yv/lKDCK3QB0a2B+q1tnvSmU9/woUFKHS3QKDCot1CQd/KsWmTN3NTUB08pRVovlw4tu/aWKrbbcCznFjnxTx80WcpRE3mjugoL3sNRl+dhDNuB1YNtKNxaeCJTLqD13IwKGVE7fa28SmSIE94S1MIkM6JEiUMXYVYR0rcVmhHz4FbDnZM6ns5mcEwo4HTY2DIVSI0dxm6j5UNTRnFpV1o2/DiJQYB0WBCTgr0yW72jp/aFh6aEAgWbrcoo8OK3n9ypwq0h2oBK3OFqIcrMXuBwyz9dWTm+CSSBue1h41VY3zQlRUNxEe1mROAAKLDsUHz9ty4siZYU3OW4URtSwVVTRSiCXU8y4xDi2Ek4AAAAj4BnmNqSf8BcC6DXP+KkbJrMjqELenju1hm9kCtnNQBDV9lz+oZcGk7OHU470GH+zhCdBMXTCvchVRgXFlH4A4W72IlSUnXjxXqHUkXEuneeTe48DSCmWz0FSmDrVf///guBFUHZF41E3gQYCgFSrKaOOCRpHM4J/Pp3B047sGY5iIBEBhfAANcO15fQceqnM21cojtkGPFy9v+Riowt2MEFL6sXWy7jDd82bzrR+7nqc0seytP77GkuAL1wjrr/w9suBl+B87sj5/B+0B98E1tpoUGHsmfrl+X09XSXRNnpah0s1+OC/O7awEZYv9wmIewyNmQpnEKu3mupsmQNt+aTwoZq5dwj7CQFzDtUPe/M/cCyG9j4uMXLdZIc0INzkSTLbsmZ0GR3ZXvzNum6yG6quG3xSGiT4Ve9XVxk7ylBhFboA6NbA/Va2z3pTKe/4UKClDpboFBhUW6hIO/lWLTJm7mpqA6eUoq0Xy4cW3ftLFVttuBZzixz4p4+aLOUoibzR3qzM2SKpXBZQPkrbzMQuFrEvMRu/W4v+sKWgCQi2CQwQOWWkCMe51Vrhrrd7YNVXUVdAtDR86XJrUJVmi/hgYan0b2DXQL8ZbgOO6fPggDZBjztiFWJshE+XV80ssEMyq7UsRFoD6CegblefGX+J1J3Wed83pBqXJMRsji2TsQ+sGfZ3TPKyu2fv9Q8sjT0BiqN+2SLFpKG/xSpfC+ggaTyIIAZVLaCpxqPtVyHR2Zas8rJ6LBdR/o4rc5AAACbEGaZUmoQWiZTA//5EAAkqEpQw3c56lkyvbBaouFybET4/yhLtur9rYGTbA1AH72jpInErHwLgNIMHTxpcvPr+XOtuisQzgarmm9sO9CULwj/5ltQKexFwuW7ImVBs02H2pPzAFXIEL5/Pp+g139ZsiX9jROXSwup2WfGm9mmFWE1smVn+XhjvkjV5ENQA3J5bR5dQ92b4xBgqicNoh+eJ/sWRdgy2AGregESm+NumjLLvVIXSjj9YSMddbvxVmwaNNneEOzIpSUcAXDDwHC32qSPFzRTDL/G0d3IWFCY3r+xEMIcY0dzuJDKAoYJ6DZ8qXZv6vvcj0lJ2h06GtW3ZV/zsgBq6EKxJR0ALJMPZpxnB+97dNQgThzYrYclbrXIlqE6ggws+RkiCAN/Rc+1d7KiVSnqTuO5h2YzZ2X1cjJfgaQCBsdOr3HdhKJJASPcFmphUfVjc3Q9nAoJOo5zBzxDYQ3QJrs1AZH8Xy7EM9trhKjuPUMvE46IHtwWRgsFe+TgqrScOI7JAtgSmIVaRaJ0EqUQMJ/kQbvSo8thFG4jktpluto1fMN9QiHZZe6ugNYXN291jGT1JkJX80GJgCLC6qKvB45gNIRavoYGaZ5XeQiWDqm7ekHeHHeQePpMdY4PvKzB0F8mBJe/YZgsEOgsxzysGQQxa0hilpzjw/jLDGuTP0cOLXxABwsYWBAv7/einhT4RADocqArXTcNtiI/0B9kgBUK+ZV2/mgYK103yuzOuwKO3ug4yzpNLbU6N6KsWXAmfp/INPkxsOxcYTjqDpdLdazVJqJh/LFgEJU2m3BTOWWjqDLnOfxAAADcm1vb3YAAABsbXZoZAAAAAAAAAAAAAAAAAAAA+gAAAu4AAEAAAEAAAAAAAAAAAAAAAABAAAAAAAAAAAAAAAAAAAAAQAAAAAAAAAAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIAAAKcdHJhawAAAFx0a2hkAAAAAwAAAAAAAAAAAAAAAQAAAAAAAAu4AAAAAAAAAAAAAAAAAAAAAAABAAAAAAAAAAAAAAAAAAAAAQAAAAAAAAAAAAAAAAAAQAAAAAEAAAABAAAAAAAAJGVkdHMAAAAcZWxzdAAAAAAAAAABAAALuAAAQAAAAQAAAAACFG1kaWEAAAAgbWRoZAAAAAAAAAAAAAAAAAAAQAAAAMAAVcQAAAAAAC1oZGxyAAAAAAAAAAB2aWRlAAAAAAAAAAAAAAAAVmlkZW9IYW5kbGVyAAAAAb9taW5mAAAAFHZtaGQAAAABAAAAAAAAAAAAAAAkZGluZgAAABxkcmVmAAAAAAAAAAEAAAAMdXJsIAAAAAEAAAF/c3RibAAAAK9zdHNkAAAAAAAAAAEAAACfYXZjMQAAAAAAAAABAAAAAAAAAAAAAAAAAAAAAAEAAQAASAAAAEgAAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABj//wAAADVhdmNDAWQADP/hABhnZAAMrNlBAIaEAAADAAQAAAMAEDxQplgBAAZo6+GyyLD9+PgAAAAAFGJ0cnQAAAAAAAEI+AABCPgAAAAYc3R0cwAAAAAAAAABAAAABgAAIAAAAAAUc3RzcwAAAAAAAAABAAAAAQAAAEBjdHRzAAAAAAAAAAYAAAABAABAAAAAAAEAAKAAAAAAAQAAQAAAAAABAAAAAAAAAAEAACAAAAAAAQAAQAAAAAAcc3RzYwAAAAAAAAABAAAAAQAAAAYAAAABAAAALHN0c3oAAAAAAAAAAAAAAAYAAFc7AAADFwAAAgsAAAJOAAACQgAAAnAAAAAUc3RjbwAAAAAAAAABAAAAMAAAAGJ1ZHRhAAAAWm1ldGEAAAAAAAAAIWhkbHIAAAAAAAAAAG1kaXJhcHBsAAAAAAAAAAAAAAAALWlsc3QAAAAlqXRvbwAAAB1kYXRhAAAAAQAAAABMYXZmNTguNzYuMTAw\" type=\"video/mp4\"/>\n",
              "      This browser does not support the video tag.\n",
              "      </video></td></tr></table>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Run this cell without modification\n",
        "\n",
        "# Visualize the learned behavior\n",
        "_, eval_info = evaluate(\n",
        "    policy=q_learning_trainer.policy,\n",
        "    num_episodes=1,\n",
        "    env_name=q_learning_trainer.env_name,\n",
        "    render=\"rgb_array\",  # Visualize the behavior here in the cell\n",
        "    sleep=0.2  # The time interval between two rendering frames\n",
        ")\n",
        "animate(eval_info[\"frames\"], fps=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e198cc0a",
      "metadata": {
        "id": "e198cc0a"
      },
      "source": [
        "## Section 3: Implement Deep Q Learning in Pytorch\n",
        "\n",
        "(30 / 100 points)\n",
        "\n",
        "In this section, we will implement a neural network and train it with Deep Q Learning via Pytorch, a powerful deep learning framework.\n",
        "\n",
        "If you are not familiar with Pytorch, we suggest you to go through pytorch official quickstart tutorials:\n",
        "1. [quickstart](https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html)\n",
        "2. [tutorial on RL](https://pytorch.org/tutorials/intermediate/reinforcement_q_learning.html)\n",
        "\n",
        "Different from the Q learning in Section 2, we will implement Deep Q Network (DQN) in this section. The main differences are summarized as follows:\n",
        "\n",
        "**DQN requires an experience replay buffer to store the transitions.** A replay memory (buffer) is implemented in the following `ExperienceReplayMemory` class. It contains a certain amount of transitions: `(s_t, a_t, r_t, s_t+1, done_t)`. When the memory is full, the earliest transition is discarded and the latest one is stored. The replay memory increases the sample efficiency (since each transition might be used multiple times) when solving complex task.\n",
        "\n",
        "\n",
        "**DQN has a delayed-updating target network.** DQN maintains another neural network called the target network that has identical architecture of the Q network. After a certain amount of learning steps has been taken, the target network copies the parameters of the Q network to itself. The update of the target network will be much less frequent than the update of the Q network.\n",
        "\n",
        "The target network is used to stabilize the estimation of the TD error. In DQN, the TD error is estimated as:\n",
        "\n",
        "$$(r_t + \\gamma \\max_{a_{t+1}} Q^{target}(s_{t+1}, a_{t+1}) - Q(s_t, a_t))$$\n",
        "\n",
        "The Q value of the next state is estimated by the target network, not the Q network that is being updated. This mechanism can reduce the variance of gradient because the next Q values is not influenced by the update of current Q network.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aa025029",
      "metadata": {
        "id": "aa025029"
      },
      "source": [
        "### Section 3.1: Build DQN trainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a87cab7",
      "metadata": {
        "id": "6a87cab7"
      },
      "outputs": [],
      "source": [
        "# Solve the TODOs and remove `pass`\n",
        "\n",
        "from collections import deque\n",
        "import random\n",
        "\n",
        "\n",
        "class ExperienceReplayMemory:\n",
        "    \"\"\"Store and sample the transitions\"\"\"\n",
        "\n",
        "    def __init__(self, capacity):\n",
        "        # deque is a useful class which acts like a list but only contain\n",
        "        # finite elements. When adding new element into the deque will make deque full with\n",
        "        # `maxlen` elements, the oldest element (the index 0 element) will be removed.\n",
        "\n",
        "        # TODO: uncomment next line.\n",
        "        self.memory = deque(maxlen=capacity)\n",
        "\n",
        "\n",
        "    def push(self, transition):\n",
        "        self.memory.append(transition)\n",
        "\n",
        "    def sample(self, batch_size):\n",
        "        return random.sample(self.memory, batch_size)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.memory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a72ec0f",
      "metadata": {
        "id": "1a72ec0f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee368876-4269-4d1f-812d-aaf07e09b7d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name of each parameter vectors:  odict_keys(['action_value.0.weight', 'action_value.0.bias', 'action_value.2.weight', 'action_value.2.bias', 'action_value.4.weight', 'action_value.4.bias'])\n",
            "Test passed!\n"
          ]
        }
      ],
      "source": [
        "# Solve the TODOs and remove `pass`\n",
        "\n",
        "class PytorchModel(nn.Module):\n",
        "    def __init__(self, num_inputs, num_outputs, hidden_units=100):\n",
        "        super(PytorchModel, self).__init__()\n",
        "\n",
        "        # TODO: Build a nn.Sequential object as the neural network with two hidden layers and one output layer.\n",
        "        #\n",
        "        # The first hidden layer takes `num_inputs`-dim vector as input and has `hidden_units` hidden units,\n",
        "        # followed by a ReLU activation function.\n",
        "        #\n",
        "        # The second hidden layer takes `hidden_units`-dim vector as input and has `hidden_units` hidden units,\n",
        "        # followed by a ReLU activation function.\n",
        "        #\n",
        "        # The output layer takes `hidden_units`-dim vector as input and returns `num_outputs`-dim vctor as output.\n",
        "        self.action_value = nn.Sequential(\n",
        "            nn.Linear(num_inputs, hidden_units),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_units, hidden_units),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_units, num_outputs)\n",
        "        )\n",
        "\n",
        "    def forward(self, obs):\n",
        "        return self.action_value(obs)\n",
        "\n",
        "\n",
        "# Test\n",
        "test_pytorch_model = PytorchModel(num_inputs=3, num_outputs=7, hidden_units=123)\n",
        "assert isinstance(test_pytorch_model.action_value, nn.Module)\n",
        "assert len(test_pytorch_model.state_dict()) == 6\n",
        "assert test_pytorch_model.state_dict()[\"action_value.0.weight\"].shape == (123, 3)\n",
        "print(\"Name of each parameter vectors: \", test_pytorch_model.state_dict().keys())\n",
        "\n",
        "print(\"Test passed!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dddbd300",
      "metadata": {
        "id": "dddbd300"
      },
      "outputs": [],
      "source": [
        "# Solve the TODOs and remove `pass`\n",
        "\n",
        "DQN_CONFIG = merge_config(dict(\n",
        "    parameter_std=0.01,\n",
        "    learning_rate=0.001,\n",
        "    hidden_dim=100,\n",
        "    clip_norm=1.0,\n",
        "    clip_gradient=True,\n",
        "    max_iteration=1000,\n",
        "    max_episode_length=1000,\n",
        "    evaluate_interval=100,\n",
        "    gamma=0.99,\n",
        "    eps=0.3,\n",
        "    memory_size=50000,\n",
        "    learn_start=5000,\n",
        "    batch_size=32,\n",
        "    target_update_freq=500,  # in steps\n",
        "    learn_freq=1,  # in steps\n",
        "    n=1,\n",
        "    env_name=\"CartPole-v1\",\n",
        "), Q_LEARNING_TRAINER_CONFIG)\n",
        "\n",
        "def to_tensor(x):\n",
        "    \"\"\"A helper function to transform a numpy array to a Pytorch Tensor\"\"\"\n",
        "    if isinstance(x, np.ndarray):\n",
        "        x = torch.from_numpy(x).type(torch.float32)\n",
        "    assert isinstance(x, torch.Tensor)\n",
        "    # The previous unsqueeze(0) logic here was problematic for already-batched 1D tensors.\n",
        "    # It's now handled explicitly in compute_values for single observations.\n",
        "    # Removed the restrictive dimension assertion for more flexibility.\n",
        "    return x\n",
        "\n",
        "\n",
        "class DQNTrainer(AbstractTrainer):\n",
        "    def __init__(self, config):\n",
        "        config = merge_config(config, DQN_CONFIG)\n",
        "        self.learning_rate = config[\"learning_rate\"]\n",
        "        super().__init__(config)\n",
        "\n",
        "        self.memory = ExperienceReplayMemory(config[\"memory_size\"])\n",
        "\n",
        "        self.learn_start = config[\"learn_start\"]\n",
        "        self.batch_size = config[\"batch_size\"]\n",
        "        self.target_update_freq = config[\"target_update_freq\"]\n",
        "        self.clip_norm = config[\"clip_norm\"]\n",
        "        self.hidden_dim = config[\"hidden_dim\"]\n",
        "        self.max_episode_length = self.config[\"max_episode_length\"]\n",
        "        self.learning_rate = self.config[\"learning_rate\"]\n",
        "        self.gamma = self.config[\"gamma\"]\n",
        "        self.n = self.config[\"n\"]\n",
        "\n",
        "        self.step_since_update = 0\n",
        "        self.total_step = 0\n",
        "\n",
        "        # You need to setup the parameter for your function approximator.\n",
        "        self.initialize_parameters()\n",
        "\n",
        "    def initialize_parameters(self):\n",
        "        # TODO: Initialize the Q network and the target network using PytorchModel class.\n",
        "        self.network = PytorchModel(self.obs_dim, self.act_dim, self.hidden_dim)\n",
        "        print(\"Setting up self.network with obs dim: {} and action dim: {}\".format(self.obs_dim, self.act_dim))\n",
        "\n",
        "        self.network.eval()\n",
        "        self.network.share_memory()\n",
        "\n",
        "        # Initialize target network to be identical to self.network.\n",
        "        # You should put the weights of self.network into self.target_network.\n",
        "        # TODO: Uncomment next few lines\n",
        "        self.target_network = PytorchModel(self.obs_dim, self.act_dim, self.hidden_dim)\n",
        "        self.target_network.load_state_dict(self.network.state_dict())\n",
        "\n",
        "\n",
        "        self.target_network.eval()\n",
        "\n",
        "        # Build Adam optimizer and MSE Loss.\n",
        "        # TODO: Uncomment next few lines\n",
        "        self.optimizer = torch.optim.Adam(\n",
        "            self.network.parameters(), lr=self.learning_rate\n",
        "        )\n",
        "        self.loss = nn.MSELoss()\n",
        "\n",
        "    def compute_values(self, processed_state):\n",
        "        \"\"\"Compute the value for each potential action. Note that you\n",
        "        should NOT preprocess the state here.\"\"\"\n",
        "        # Add a batch dimension to the single processed_state, then squeeze it from the output\n",
        "        values = self.network(processed_state.unsqueeze(0)).detach().numpy().squeeze(0)\n",
        "        return values\n",
        "\n",
        "    def compute_action(self, processed_state, eps=None):\n",
        "        \"\"\"Compute the action given the state. Note that the input\n",
        "        is the processed state.\"\"\"\n",
        "        values = self.compute_values(processed_state)\n",
        "        assert values.ndim == 1, values.shape\n",
        "\n",
        "        if eps is None:\n",
        "            eps = self.eps\n",
        "\n",
        "        if np.random.uniform(0, 1) < eps:\n",
        "            action = self.env.action_space.sample()\n",
        "        else:\n",
        "            action = np.argmax(values)\n",
        "        return action\n",
        "\n",
        "    def train(self, iteration=None):\n",
        "        iteration_string = \"\" if iteration is None else f\"Iter {iteration}: \"\n",
        "        obs, info = self.env.reset()\n",
        "        processed_obs = self.process_state(obs)\n",
        "        act = self.compute_action(processed_obs)\n",
        "\n",
        "        stat = {\"loss\": [], \"success_rate\": np.nan}\n",
        "\n",
        "        for t in range(self.max_episode_length):\n",
        "            next_obs, reward, terminated, truncated, info = self.env.step(act)\n",
        "            done = terminated or truncated\n",
        "\n",
        "            next_processed_obs = self.process_state(next_obs)\n",
        "\n",
        "            # Push the transition into memory.\n",
        "            self.memory.push(\n",
        "                (processed_obs, act, reward, next_processed_obs, done)\n",
        "            )\n",
        "\n",
        "            processed_obs = next_processed_obs\n",
        "            act = self.compute_action(next_processed_obs)\n",
        "            self.step_since_update += 1\n",
        "            self.total_step += 1\n",
        "\n",
        "            if done:\n",
        "                if \"arrive_dest\" in info:\n",
        "                    stat[\"success_rate\"] = info[\"arrive_dest\"]\n",
        "                break\n",
        "\n",
        "            if t % self.config[\"learn_freq\"] != 0:\n",
        "                # It's not necessary to update policy in each environmental interaction.\n",
        "                continue\n",
        "\n",
        "            if len(self.memory) < self.learn_start:\n",
        "                continue\n",
        "            elif len(self.memory) == self.learn_start:\n",
        "                logging.info(\n",
        "                    \"{}Current memory contains {} transitions, \"\n",
        "                    \"start learning!\".format(iteration_string, self.learn_start)\n",
        "                )\n",
        "\n",
        "            batch = self.memory.sample(self.batch_size)\n",
        "\n",
        "            # Transform a batch of elements in transitions into tensors.\n",
        "            state_batch = to_tensor(\n",
        "                np.stack([transition[0] for transition in batch])\n",
        "            )\n",
        "            action_batch = to_tensor(\n",
        "                np.stack([transition[1] for transition in batch])\n",
        "            )\n",
        "            reward_batch = to_tensor(\n",
        "                np.stack([transition[2] for transition in batch])\n",
        "            )\n",
        "            next_state_batch = torch.stack(\n",
        "                [transition[3] for transition in batch]\n",
        "            )\n",
        "            done_batch = to_tensor(\n",
        "                np.stack([transition[4] for transition in batch])\n",
        "            )\n",
        "\n",
        "            with torch.no_grad():\n",
        "                # TODO: Compute the Q values for the next states by calling target network.\n",
        "                Q_t_plus_one = self.target_network(next_state_batch).max(1)[0]\n",
        "\n",
        "                assert isinstance(Q_t_plus_one, torch.Tensor)\n",
        "\n",
        "                # TODO: Compute the target values for current state.\n",
        "                # The Q_objective will be used as the objective in the loss function.\n",
        "                # Hint: Remember to use done_batch.\n",
        "                Q_objective = reward_batch + self.gamma * Q_t_plus_one * (1 - done_batch)\n",
        "\n",
        "                assert Q_objective.shape == (self.batch_size,)\n",
        "\n",
        "            self.network.train()  # Set the network to \"train\" mode.\n",
        "\n",
        "            # TODO: Collect the Q values in batch.\n",
        "            # Hint: The network will return the Q values for all actions at a given state.\n",
        "            #  So we need to \"extract\" the Q value for the action we've taken.\n",
        "            #  You need to use torch.gather to manipulate the 2nd dimension of the return\n",
        "            #  tensor from the network and extract the desired Q values.\n",
        "            Q_t = self.network(state_batch).gather(1, action_batch.long().unsqueeze(1)).squeeze(1)\n",
        "\n",
        "            assert Q_t.shape == Q_objective.shape\n",
        "\n",
        "            # Update the network\n",
        "            self.optimizer.zero_grad()\n",
        "            loss = self.loss(input=Q_t, target=Q_objective)\n",
        "            stat['loss'].append(loss.item())\n",
        "            loss.backward()\n",
        "\n",
        "            # TODO: Apply gradient clipping with pytorch utility. Uncomment next line.\n",
        "            nn.utils.clip_grad_norm_(self.network.parameters(), self.clip_norm)\n",
        "\n",
        "            self.optimizer.step()\n",
        "            self.network.eval()\n",
        "\n",
        "        if len(self.memory) >= self.learn_start and \\\n",
        "                self.step_since_update > self.target_update_freq:\n",
        "            self.step_since_update = 0\n",
        "\n",
        "            # TODO: Copy the weights of self.network to self.target_network.\n",
        "            self.target_network.load_state_dict(self.network.state_dict())\n",
        "\n",
        "            self.target_network.eval()\n",
        "\n",
        "        ret = {\"loss\": np.mean(stat[\"loss\"]), \"episode_len\": t}\n",
        "        if \"success_rate\" in stat:\n",
        "            ret[\"success_rate\"] = stat[\"success_rate\"]\n",
        "        return ret\n",
        "\n",
        "    def process_state(self, state):\n",
        "        return torch.from_numpy(state).type(torch.float32)\n",
        "\n",
        "    def save(self, loc=\"model.pt\"):\n",
        "        torch.save(self.network.state_dict(), loc)\n",
        "\n",
        "    def load(self, loc=\"model.pt\"):\n",
        "        self.network.load_state_dict(torch.load(loc))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "45f6fabd",
      "metadata": {
        "id": "45f6fabd"
      },
      "source": [
        "### Section 3.2: Test DQN trainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "30d4a27d",
      "metadata": {
        "id": "30d4a27d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "630960f3-7e54-41aa-dd08-104ed9890bda"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/numpy/_core/fromnumeric.py:3596: RuntimeWarning: Mean of empty slice.\n",
            "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
            "/usr/local/lib/python3.12/dist-packages/numpy/_core/_methods.py:138: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting up self.network with obs dim: 4 and action dim: 2\n",
            "Now your codes should be bug-free.\n",
            "Setting up self.network with obs dim: 4 and action dim: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   0%|          | 0/21 [00:00<?, ?it/s, ep_reward=9.4]INFO:root:Iter 8: Current memory contains 100 transitions, start learning!\n",
            "Training: 100%|██████████| 21/21 [00:00<00:00, 36.59it/s, ep_reward=9.6]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Environment is closed.\n",
            "Test passed!\n"
          ]
        }
      ],
      "source": [
        "# Run this cell without modification\n",
        "\n",
        "# Build the test trainer.\n",
        "test_trainer = DQNTrainer({})\n",
        "\n",
        "# Test compute_values\n",
        "fake_state = test_trainer.env.observation_space.sample()\n",
        "processed_state = test_trainer.process_state(fake_state)\n",
        "assert processed_state.shape == (test_trainer.obs_dim,), processed_state.shape\n",
        "values = test_trainer.compute_values(processed_state)\n",
        "assert values.shape == (test_trainer.act_dim,), values.shape\n",
        "\n",
        "test_trainer.train()\n",
        "print(\"Now your codes should be bug-free.\")\n",
        "\n",
        "_ = run(DQNTrainer, dict(\n",
        "    max_iteration=20,\n",
        "    evaluate_interval=10,\n",
        "    learn_start=100,\n",
        "    env_name=\"CartPole-v1\",\n",
        "))\n",
        "\n",
        "test_trainer.save(\"test_trainer.pt\")\n",
        "test_trainer.load(\"test_trainer.pt\")\n",
        "\n",
        "print(\"Test passed!\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "98027998",
        "outputId": "8e9ff457-691c-4861-b28d-645d773d87f7"
      },
      "source": [
        "# Run this cell without modification\n",
        "\n",
        "# Build the test trainer.\n",
        "test_trainer = DQNTrainer({})\n",
        "\n",
        "# Test compute_values\n",
        "fake_state = test_trainer.env.observation_space.sample()\n",
        "processed_state = test_trainer.process_state(fake_state)\n",
        "assert processed_state.shape == (test_trainer.obs_dim,), processed_state.shape\n",
        "values = test_trainer.compute_values(processed_state)\n",
        "assert values.shape == (test_trainer.act_dim,), values.shape\n",
        "\n",
        "test_trainer.train()\n",
        "print(\"Now your codes should be bug-free.\")\n",
        "\n",
        "_ = run(DQNTrainer, dict(\n",
        "    max_iteration=20,\n",
        "    evaluate_interval=10,\n",
        "    learn_start=100,\n",
        "    env_name=\"CartPole-v1\",\n",
        "))\n",
        "\n",
        "test_trainer.save(\"test_trainer.pt\")\n",
        "test_trainer.load(\"test_trainer.pt\")\n",
        "\n",
        "print(\"Test passed!\")"
      ],
      "id": "98027998",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting up self.network with obs dim: 4 and action dim: 2\n",
            "Now your codes should be bug-free.\n",
            "Setting up self.network with obs dim: 4 and action dim: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   0%|          | 0/21 [00:00<?, ?it/s, ep_reward=9.4]INFO:root:Iter 10: Current memory contains 100 transitions, start learning!\n",
            "Training: 100%|██████████| 21/21 [00:00<00:00, 41.08it/s, ep_reward=9.4]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Environment is closed.\n",
            "Test passed!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff767ce5",
      "metadata": {
        "id": "ff767ce5"
      },
      "source": [
        "### Section 3.3: Train DQN agents in CartPole"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a53bf178",
      "metadata": {
        "id": "a53bf178"
      },
      "source": [
        "First, we visualize a random agent in CartPole environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0221e34d",
      "metadata": {
        "id": "0221e34d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        },
        "outputId": "66af5c90-2e17-4b1c-cb15-94c17fbc98c0"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table class=\"show_videos\" style=\"border-spacing:0px;\"><tr><td style=\"padding:1px;\"><video controls width=\"600\" height=\"400\" style=\"object-fit:cover;\" loop autoplay muted>\n",
              "      <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\"/>\n",
              "      This browser does not support the video tag.\n",
              "      </video></td></tr></table>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A random agent achieves 17.0 return.\n"
          ]
        }
      ],
      "source": [
        "# Run this cell without modification\n",
        "\n",
        "eval_reward, eval_info = evaluate(\n",
        "    policy=lambda x: np.random.randint(2),\n",
        "    num_episodes=1,\n",
        "    env_name=\"CartPole-v1\",\n",
        "    render=\"rgb_array\",  # Visualize the behavior here in the cell\n",
        ")\n",
        "\n",
        "animate(eval_info[\"frames\"])\n",
        "\n",
        "print(\"A random agent achieves {} return.\".format(eval_reward))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "957a5dbc",
      "metadata": {
        "id": "957a5dbc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6bb13ac8-6061-4aaf-bd59-64ca38b9a604"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting up self.network with obs dim: 4 and action dim: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  64%|██████▍   | 3200/5001 [03:11<04:58,  6.03it/s, ep_reward=452]INFO:root:Iter 3200, episodic return 451.800 is greater than reward threshold 450.0. Congratulation! Now we exit the training process.\n",
            "Training:  64%|██████▍   | 3200/5001 [03:11<01:47, 16.70it/s, ep_reward=452]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Environment is closed.\n"
          ]
        }
      ],
      "source": [
        "# Run this cell without modification\n",
        "\n",
        "pytorch_trainer, pytorch_stat = run(DQNTrainer, dict(\n",
        "    max_iteration=5000,\n",
        "    evaluate_interval=100,\n",
        "    learning_rate=0.001,\n",
        "    clip_norm=10.0,\n",
        "    memory_size=50000,\n",
        "    learn_start=1000,\n",
        "    eps=0.1,\n",
        "    target_update_freq=2000,\n",
        "    batch_size=128,\n",
        "    learn_freq=32,\n",
        "    env_name=\"CartPole-v1\",\n",
        "), reward_threshold=450.0)\n",
        "\n",
        "reward, _ = pytorch_trainer.evaluate()\n",
        "assert reward > 400.0, \"Check your codes. \" \\\n",
        "                       \"Your agent should achieve {} reward in 5000 iterations.\" \\\n",
        "                       \"But it achieve {} reward in evaluation.\".format(400.0, reward)\n",
        "\n",
        "pytorch_trainer.save(\"dqn_trainer_cartpole.pt\")\n",
        "\n",
        "# Should solve the task in 10 minutes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66a4cf9a",
      "metadata": {
        "id": "66a4cf9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        },
        "outputId": "e7a85940-3083-4a0b-f547-03cc657e5152"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table class=\"show_videos\" style=\"border-spacing:0px;\"><tr><td style=\"padding:1px;\"><video controls width=\"600\" height=\"400\" style=\"object-fit:cover;\" loop autoplay muted>\n",
              "      <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\"/>\n",
              "      This browser does not support the video tag.\n",
              "      </video></td></tr></table>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DQN agent achieves 500.0 return.\n"
          ]
        }
      ],
      "source": [
        "# Run this cell without modification\n",
        "\n",
        "# Render the learned behavior\n",
        "eval_reward, eval_info = evaluate(\n",
        "    policy=pytorch_trainer.policy,\n",
        "    num_episodes=1,\n",
        "    env_name=pytorch_trainer.env_name,\n",
        "    render=\"rgb_array\",  # Visualize the behavior here in the cell\n",
        ")\n",
        "\n",
        "animate(eval_info[\"frames\"])\n",
        "\n",
        "print(\"DQN agent achieves {} return.\".format(eval_reward))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "98b60f6c",
      "metadata": {
        "id": "98b60f6c"
      },
      "source": [
        "### Section 3.4: Train DQN agents in MetaDrive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e93c9cea",
      "metadata": {
        "id": "e93c9cea"
      },
      "outputs": [],
      "source": [
        "# Run this cell without modification\n",
        "\n",
        "def register_metadrive():\n",
        "    try:\n",
        "        from metadrive.envs import MetaDriveEnv\n",
        "        from metadrive.utils.config import merge_config_with_unknown_keys\n",
        "    except ImportError as e:\n",
        "        print(\"Please install MetaDrive through: pip install git+https://github.com/metadriverse/metadrive\")\n",
        "        raise e\n",
        "\n",
        "    env_names = []\n",
        "    try:\n",
        "        class MetaDriveEnvTut(gym.Wrapper):\n",
        "            def __init__(self, config, *args, render_mode=None, **kwargs):\n",
        "                # Ignore render_mode\n",
        "                self._render_mode = render_mode\n",
        "                super().__init__(MetaDriveEnv(config))\n",
        "                self.env.logger.setLevel(logging.FATAL)\n",
        "                self.action_space = gym.spaces.Discrete(int(np.prod(self.env.action_space.n)))\n",
        "\n",
        "            def reset(self, *args, seed=None, render_mode=None, options=None, **kwargs):\n",
        "                # Ignore seed and render_mode\n",
        "                return self.env.reset(*args, **kwargs)\n",
        "\n",
        "            def render(self):\n",
        "                return self.env.render(mode=self._render_mode)\n",
        "\n",
        "        def _make_env(*args, **kwargs):\n",
        "            return MetaDriveEnvTut(*args, **kwargs)\n",
        "\n",
        "        env_name = \"MetaDrive-Tut-Easy-v0\"\n",
        "        gym.register(id=env_name, entry_point=_make_env, kwargs={\"config\": dict(\n",
        "            map=\"S\",\n",
        "            start_seed=0,\n",
        "            num_scenarios=1,\n",
        "            horizon=200,\n",
        "            discrete_action=True,\n",
        "            discrete_steering_dim=3,\n",
        "            discrete_throttle_dim=3\n",
        "        )})\n",
        "        env_names.append(env_name)\n",
        "\n",
        "        env_name = \"MetaDrive-Tut-Hard-v0\"\n",
        "        gym.register(id=env_name, entry_point=_make_env, kwargs={\"config\": dict(\n",
        "            map=\"CCC\",\n",
        "            start_seed=0,\n",
        "            num_scenarios=10,\n",
        "            discrete_action=True,\n",
        "            discrete_steering_dim=5,\n",
        "            discrete_throttle_dim=5\n",
        "        )})\n",
        "        env_names.append(env_name)\n",
        "    except gym.error.Error as e:\n",
        "        print(\"Information when registering MetaDrive: \", e)\n",
        "    else:\n",
        "        print(\"Successfully registered MetaDrive environments: \", env_names)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89fb5d1e",
      "metadata": {
        "id": "89fb5d1e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "826555fb-e528-4114-c934-70ac4c66b4a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:OpenGL.acceleratesupport:No OpenGL_accelerate module loaded: No module named 'OpenGL_accelerate'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully registered MetaDrive environments:  ['MetaDrive-Tut-Easy-v0', 'MetaDrive-Tut-Hard-v0']\n"
          ]
        }
      ],
      "source": [
        "# Run this cell without modification\n",
        "\n",
        "register_metadrive()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b580ec99",
      "metadata": {
        "id": "b580ec99",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6856004a-3bb0-4c17-d688-ad631360f7f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[38;20m[INFO] Environment: MetaDriveEnv\u001b[0m\n",
            "\u001b[38;20m[INFO] MetaDrive version: 0.4.3\u001b[0m\n",
            "\u001b[38;20m[INFO] Sensors: [lidar: Lidar(), side_detector: SideDetector(), lane_line_detector: LaneLineDetector()]\u001b[0m\n",
            "\u001b[38;20m[INFO] Render Mode: none\u001b[0m\n",
            "\u001b[38;20m[INFO] Horizon (Max steps per agent): 200\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting up self.network with obs dim: 259 and action dim: 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/numpy/_core/fromnumeric.py:3596: RuntimeWarning: Mean of empty slice.\n",
            "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
            "/usr/local/lib/python3.12/dist-packages/numpy/_core/_methods.py:138: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Now your codes should be bug-free.\n"
          ]
        }
      ],
      "source": [
        "# Run this cell without modification\n",
        "\n",
        "# Build the test trainer.\n",
        "test_trainer = DQNTrainer(dict(env_name=\"MetaDrive-Tut-Easy-v0\"))\n",
        "\n",
        "# Test compute_values\n",
        "for _ in range(10):\n",
        "    fake_state = test_trainer.env.observation_space.sample()\n",
        "    processed_state = test_trainer.process_state(fake_state)\n",
        "    assert processed_state.shape == (test_trainer.obs_dim,), processed_state.shape\n",
        "    values = test_trainer.compute_values(processed_state)\n",
        "    assert values.shape == (test_trainer.act_dim,), values.shape\n",
        "\n",
        "    test_trainer.train()\n",
        "\n",
        "print(\"Now your codes should be bug-free.\")\n",
        "test_trainer.env.close()\n",
        "del test_trainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "675c9809",
      "metadata": {
        "id": "675c9809",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "724ca985-0541-4b28-b1f7-027b2aa05159"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[38;20m[INFO] Environment: MetaDriveEnv\u001b[0m\n",
            "\u001b[38;20m[INFO] MetaDrive version: 0.4.3\u001b[0m\n",
            "\u001b[38;20m[INFO] Sensors: [lidar: Lidar(), side_detector: SideDetector(), lane_line_detector: LaneLineDetector()]\u001b[0m\n",
            "\u001b[38;20m[INFO] Render Mode: none\u001b[0m\n",
            "\u001b[38;20m[INFO] Horizon (Max steps per agent): 200\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting up self.network with obs dim: 259 and action dim: 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   1%|▏         | 70/5001 [00:23<21:31,  3.82it/s, ep_reward=125]  INFO:root:Iter 70, episodic return 125.053 is greater than reward threshold 120. Congratulation! Now we exit the training process.\n",
            "Training:   1%|▏         | 70/5001 [00:23<27:13,  3.02it/s, ep_reward=125]\n",
            "\u001b[38;20m[INFO] Environment: MetaDriveEnv\u001b[0m\n",
            "\u001b[38;20m[INFO] MetaDrive version: 0.4.3\u001b[0m\n",
            "\u001b[38;20m[INFO] Sensors: [lidar: Lidar(), side_detector: SideDetector(), lane_line_detector: LaneLineDetector()]\u001b[0m\n",
            "\u001b[38;20m[INFO] Render Mode: none\u001b[0m\n",
            "\u001b[38;20m[INFO] Horizon (Max steps per agent): 200\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Environment is closed.\n",
            "Evaluating 1/1 episodes. We are in 1/1000 steps. Current episode reward: 0.008\n",
            "Evaluating 1/1 episodes. We are in 51/1000 steps. Current episode reward: 37.142\n",
            "DQN agent achieves 125.05254010105511 return in MetaDrive easy environment.\n"
          ]
        }
      ],
      "source": [
        "# Run this cell without modification\n",
        "\n",
        "env_name = \"MetaDrive-Tut-Easy-v0\"\n",
        "\n",
        "pytorch_trainer2, _ = run(DQNTrainer, dict(\n",
        "    max_episode_length=200,\n",
        "    max_iteration=5000,\n",
        "    evaluate_interval=10,\n",
        "    evaluate_num_episodes=10,\n",
        "    learning_rate=0.0001,\n",
        "    clip_norm=10.0,\n",
        "    memory_size=1000000,\n",
        "    learn_start=2000,\n",
        "    eps=0.1,\n",
        "    target_update_freq=5000,\n",
        "    learn_freq=16,\n",
        "    batch_size=256,\n",
        "    env_name=env_name\n",
        "), reward_threshold=120)\n",
        "\n",
        "pytorch_trainer2.save(\"dqn_trainer_metadrive_easy.pt\")\n",
        "\n",
        "# Run this cell without modification\n",
        "\n",
        "# Render the learned behavior\n",
        "# NOTE: The learned agent is marked by green color.\n",
        "eval_reward, eval_info = evaluate(\n",
        "    policy=pytorch_trainer2.policy,\n",
        "    num_episodes=1,\n",
        "    env_name=pytorch_trainer2.env_name,\n",
        "    render=\"topdown\",  # Visualize the behaviors in top-down view\n",
        "    verbose=True\n",
        ")\n",
        "print(\"DQN agent achieves {} return in MetaDrive easy environment.\".format(eval_reward))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4df9a42-c02a-4122-808a-9b04b2d8056a",
      "metadata": {
        "id": "f4df9a42-c02a-4122-808a-9b04b2d8056a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 823
        },
        "outputId": "4fb10533-9530-47df-dc0c-a336f5332acd"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table class=\"show_videos\" style=\"border-spacing:0px;\"><tr><td style=\"padding:1px;\"><video controls width=\"800\" height=\"800\" style=\"object-fit:cover;\" loop autoplay muted>\n",
              "      <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\"/>\n",
              "      This browser does not support the video tag.\n",
              "      </video></td></tr></table>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Run this cell directly.\n",
        "\n",
        "# Visualize MetaDrive performance\n",
        "animate(eval_info[\"frames\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2c86871e",
      "metadata": {
        "id": "2c86871e"
      },
      "source": [
        "## Section 4: Policy gradient methods - REINFORCE\n",
        "\n",
        "(30 / 100 points)\n",
        "\n",
        "Unlike the supervised learning, in RL, the optimization objective, the episodic return, is not differentiable w.r.t. the neural network parameters. This can be solved via ***Policy Gradient***. It can be proved that policy gradient is an unbiased estimator of the gradient of the objective.\n",
        "\n",
        "Concretely, let's consider such optimization objective:\n",
        "\n",
        "$$Q = \\mathbb E_{\\text{possible trajectories}} \\sum_t r(a_t, s_t) = \\sum_{s_0, a_0,..} p(s_0, a_0, ..., s_t, a_t) r(s_0, a_0, ..., s_t, a_t) = \\sum_{\\tau} p(\\tau)r(\\tau)$$\n",
        "\n",
        "wherein $\\sum_t r(a_t, s_t) = r(\\tau)$ is the return of trajectory $\\tau = (s_0, a_0, ...)$. We remove the discount factor for simplicity.\n",
        "Since we want to maximize Q, we can simply compute the gradient of Q w.r.t. parameter $\\theta$ (which is implictly included in $p(\\tau)$):\n",
        "\n",
        "$$\\nabla_\\theta Q = \\nabla_\\theta \\sum_{\\tau} p(\\tau)r(\\tau) = \\sum_{\\tau} r(\\tau) \\nabla_\\theta p(\\tau)$$\n",
        "\n",
        "wherein we've applied a famous trick: $\\nabla_\\theta p(\\tau) = p(\\tau)\\cfrac{\\nabla_\\theta p(\\tau)}{p(\\tau)} = p(\\tau)\\nabla_\\theta \\log p(\\tau)$. Here the $r(\\tau)$ will be determined when $\\tau$ is determined. So it has nothing to do with the policy. We can move it out from the gradient.\n",
        "\n",
        "Introducing a log term can change the product of probabilities to sum of log probabilities. Now we can expand the log of product above to sum of log:\n",
        "\n",
        "$$p_\\theta(\\tau) = p(s_0, a_0, ...) = p(s_0) \\prod_t \\pi_\\theta (a_t|s_t) p(s_{t+1}|s_t, a_t)$$\n",
        "\n",
        "$$\\log p_\\theta (\\tau) = \\log p(s_0) + \\sum_t \\log \\pi_\\theta(a_t|s_t) + \\sum_t \\log p(s_{t+1}|s_t, a_t)$$\n",
        "\n",
        "You can find that the first and third term are not correlated to the parameter of policy $\\pi_\\theta(\\cdot)$. So when we compute $\\nabla_\\theta Q$, we find\n",
        "\n",
        "$$\\nabla_\\theta Q =\n",
        "\\sum_{\\tau} r(\\tau) \\nabla_\\theta p(\\tau) =  \n",
        "\\sum_{\\tau} r(\\tau) p(\\tau)\\nabla_\\theta \\log p(\\tau) =\n",
        "\\sum p_\\theta(\\tau) ( \\sum_t  \\nabla_\\theta \\log \\pi_\\theta(a_t|s_t) ) r(\\tau) d\\tau$$\n",
        "\n",
        "When we sample sufficient amount of data from the environment, the above equation can be estimated via:\n",
        "\n",
        "$$\\nabla_\\theta Q =\\cfrac{1}{N}\\sum_{i=1}^N [( \\sum_t  \\nabla_\\theta \\log \\pi_\\theta(a_{i,t}|s_{i,t}) (\\sum_{t'=t} \\gamma^{t'-t} r(s_{i,t'}, a_{i,t'}) )]$$\n",
        "\n",
        "This algorithm is called REINFORCE algorithm, which is a Monte Carlo Policy Gradient algorithm with long history. In this section, we will implement the it using pytorch."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3f3f6bf3",
      "metadata": {
        "id": "3f3f6bf3"
      },
      "source": [
        "The policy network is composed by two parts:\n",
        "\n",
        "1. A basic neural network serves as the function approximator. It outputs raw values parameterizing the action distribution given current observation. We will reuse PytorchModel here.\n",
        "2. A distribution layer builds upon the neural network to wrap the raw logits output from neural network to a distribution and provides API for sampling action and computing log probability."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "20b067b5",
      "metadata": {
        "id": "20b067b5"
      },
      "source": [
        "### Section 4.1: Build REINFORCE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82ccbd96",
      "metadata": {
        "id": "82ccbd96"
      },
      "outputs": [],
      "source": [
        "import torch.distributions\n",
        "\n",
        "class PGNetwork(nn.Module):\n",
        "    def __init__(self, obs_dim, act_dim, hidden_units=128):\n",
        "        super(PGNetwork, self).__init__()\n",
        "        self.network = PytorchModel(obs_dim, act_dim, hidden_units)\n",
        "\n",
        "    def forward(self, obs):\n",
        "        logit = self.network(obs)\n",
        "\n",
        "        # TODO: Create an object of the class \"torch.distributions.Categorical\"\n",
        "        # Then sample an action from it.\n",
        "        distribution = torch.distributions.Categorical(logits=logit)\n",
        "        action = distribution.sample()\n",
        "\n",
        "        return action\n",
        "\n",
        "    def log_prob(self, obs, act):\n",
        "        logits = self.network(obs)\n",
        "\n",
        "        # TODO: Create an object of the class \"torch.distributions.Categorical\"\n",
        "        # Then get the log probability of the action `act` in this distribution.\n",
        "        distribution = torch.distributions.Categorical(logits=logits)\n",
        "        log_prob = distribution.log_prob(act)\n",
        "\n",
        "        return log_prob\n",
        "\n",
        "# Note that we do not implement GaussianPolicy here. So we can't\n",
        "# apply our algorithm to the environment with continous action."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d772f93",
      "metadata": {
        "id": "3d772f93"
      },
      "outputs": [],
      "source": [
        "PG_DEFAULT_CONFIG = merge_config(dict(\n",
        "    normalize_advantage=True,\n",
        "    max_episode_length=1000,\n",
        "    clip_norm=10.0,\n",
        "    clip_gradient=True,\n",
        "    hidden_units=100,\n",
        "    max_iteration=1000,\n",
        "    train_batch_size=1000,\n",
        "    gamma=0.99,\n",
        "    learning_rate=0.001,\n",
        "    env_name=\"CartPole-v1\",\n",
        "), DEFAULT_CONFIG)\n",
        "\n",
        "\n",
        "class PGTrainer(AbstractTrainer):\n",
        "    def __init__(self, config=None):\n",
        "        config = merge_config(config, PG_DEFAULT_CONFIG)\n",
        "        self.gamma = config[\"gamma\"]\n",
        "        super().__init__(config)\n",
        "\n",
        "        self.iteration = 0\n",
        "        self.start_time = time.time()\n",
        "        self.iteration_time = self.start_time\n",
        "        self.total_timesteps = 0\n",
        "        self.total_episodes = 0\n",
        "\n",
        "        # build the model\n",
        "        self.initialize_parameters()\n",
        "\n",
        "    def initialize_parameters(self):\n",
        "        \"\"\"Build the policy network and related optimizer\"\"\"\n",
        "        # Detect whether you have GPU or not. Remember to call X.to(self.device)\n",
        "        # if necessary.\n",
        "        self.device = torch.device(\n",
        "            \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "        )\n",
        "\n",
        "        # TODO Build the policy network using CategoricalPolicy\n",
        "        # Hint: Remember to pass config[\"hidden_units\"], and set policy network\n",
        "        #  to the device you are using.\n",
        "        self.network = PGNetwork(self.obs_dim, self.act_dim, self.config[\"hidden_units\"]).to(self.device)\n",
        "\n",
        "        # Build the Adam optimizer.\n",
        "        self.optimizer = torch.optim.Adam(\n",
        "            self.network.parameters(),\n",
        "            lr=self.config[\"learning_rate\"]\n",
        "        )\n",
        "\n",
        "    def to_tensor(self, array):\n",
        "        \"\"\"Transform a numpy array to a pytorch tensor\"\"\"\n",
        "        return torch.from_numpy(array).type(torch.float32).to(self.device)\n",
        "\n",
        "    def to_array(self, tensor):\n",
        "        \"\"\"Transform a pytorch tensor to a numpy array\"\"\"\n",
        "        ret = tensor.cpu().detach().numpy()\n",
        "        if ret.size == 1:\n",
        "            ret = ret.item()\n",
        "        return ret\n",
        "\n",
        "    def save(self, loc=\"model.pt\"):\n",
        "        torch.save(self.network.state_dict(), loc)\n",
        "\n",
        "    def load(self, loc=\"model.pt\"):\n",
        "        self.network.load_state_dict(torch.load(loc))\n",
        "\n",
        "    def compute_action(self, observation, eps=None):\n",
        "        \"\"\"Compute the action for single observation. eps is useless here.\"\"\"\n",
        "        assert observation.ndim == 1\n",
        "        # TODO: Sample an action from the action distribution given by the policy.\n",
        "        # Hint: The input of policy network is a tensor with the first dimension to the\n",
        "        #  batch dimension. Therefore you need to expand the first dimension of the observation\n",
        "        #  and convert it to a tensor (via to_tensor) before feeding it to the policy network.\n",
        "        #  Then, you need to unbatch the output action and convert it from a tensor to a numpy\n",
        "        #  array before returning.\n",
        "        with torch.no_grad():\n",
        "            obs_tensor = self.to_tensor(observation).unsqueeze(0)\n",
        "            action = self.to_array(self.network(obs_tensor).squeeze(0))\n",
        "\n",
        "        return action\n",
        "\n",
        "    def compute_log_probs(self, observation, action):\n",
        "        \"\"\"Compute the log probabilities of a batch of state-action pair\"\"\"\n",
        "        # TODO: Use the function of policy network to get log probs.\n",
        "        # Hint: Remember to transform the data into tensor before feeding it into the network.\n",
        "        obs_tensor = self.to_tensor(observation)\n",
        "        act_tensor = self.to_tensor(action)\n",
        "        log_probs = self.network.log_prob(obs_tensor, act_tensor)\n",
        "\n",
        "        return log_probs\n",
        "\n",
        "    def update_network(self, processed_samples):\n",
        "        \"\"\"Update the policy network\"\"\"\n",
        "        advantages = self.to_tensor(processed_samples[\"advantages\"])\n",
        "        flat_obs = np.concatenate(processed_samples[\"obs\"])\n",
        "        flat_act = np.concatenate(processed_samples[\"act\"])\n",
        "\n",
        "        self.network.train()\n",
        "        self.optimizer.zero_grad()\n",
        "\n",
        "        log_probs = self.compute_log_probs(flat_obs, flat_act)\n",
        "\n",
        "        assert log_probs.shape == advantages.shape, \"log_probs shape {} is not \" \\\n",
        "                                                    \"compatible with advantages {}\".format(log_probs.shape,\n",
        "                                                                                           advantages.shape)\n",
        "\n",
        "        # TODO: Compute the policy gradient loss.\n",
        "        loss = -torch.mean(log_probs * advantages)\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the gradient\n",
        "        torch.nn.utils.clip_grad_norm_(\n",
        "            self.network.parameters(), self.config[\"clip_gradient\"]\n",
        "        )\n",
        "\n",
        "        self.optimizer.step()\n",
        "        self.network.eval()\n",
        "\n",
        "        update_info = {\n",
        "            \"policy_loss\": loss.item(),\n",
        "            \"mean_log_prob\": torch.mean(log_probs).item(),\n",
        "            \"mean_advantage\": torch.mean(advantages).item()\n",
        "        }\n",
        "        return update_info\n",
        "\n",
        "    # ===== Training-related functions =====\n",
        "    def collect_samples(self):\n",
        "        \"\"\"Here we define the pipeline to collect sample even though\n",
        "        any specify functions are not implemented yet.\n",
        "        \"\"\"\n",
        "        iter_timesteps = 0\n",
        "        iter_episodes = 0\n",
        "        episode_lens = []\n",
        "        episode_rewards = []\n",
        "        episode_obs_list = []\n",
        "        episode_act_list = []\n",
        "        episode_reward_list = []\n",
        "        success_list = []\n",
        "        while iter_timesteps <= self.config[\"train_batch_size\"]:\n",
        "            obs_list, act_list, reward_list = [], [], []\n",
        "            obs, info = self.env.reset()\n",
        "            steps = 0\n",
        "            episode_reward = 0\n",
        "            while True:\n",
        "                act = self.compute_action(obs)\n",
        "\n",
        "                next_obs, reward, terminated, truncated, step_info = self.env.step(act)\n",
        "                done = terminated or truncated\n",
        "\n",
        "                obs_list.append(obs)\n",
        "                act_list.append(act)\n",
        "                reward_list.append(reward)\n",
        "\n",
        "                obs = next_obs.copy()\n",
        "                steps += 1\n",
        "                episode_reward += reward\n",
        "                if done or steps > self.config[\"max_episode_length\"]:\n",
        "                    if \"arrive_dest\" in step_info:\n",
        "                        success_list.append(step_info[\"arrive_dest\"])\n",
        "                    break\n",
        "            iter_timesteps += steps\n",
        "            iter_episodes += 1\n",
        "            episode_rewards.append(episode_reward)\n",
        "            episode_lens.append(steps)\n",
        "            episode_obs_list.append(np.array(obs_list, dtype=np.float32))\n",
        "            episode_act_list.append(np.array(act_list, dtype=np.float32))\n",
        "            episode_reward_list.append(np.array(reward_list, dtype=np.float32))\n",
        "\n",
        "        # The return `samples` is a dict that contains several key-value pair.\n",
        "        # The value of each key-value pair is a list storing the data in one episode.\n",
        "        samples = {\n",
        "            \"obs\": episode_obs_list,\n",
        "            \"act\": episode_act_list,\n",
        "            \"reward\": episode_reward_list\n",
        "        }\n",
        "\n",
        "        sample_info = {\n",
        "            \"iter_timesteps\": iter_timesteps,\n",
        "            \"iter_episodes\": iter_episodes,\n",
        "            \"performance\": np.mean(episode_rewards),  # help drawing figures\n",
        "            \"ep_len\": float(np.mean(episode_lens)),\n",
        "            \"ep_ret\": float(np.mean(episode_rewards)),\n",
        "            \"episode_len\": sum(episode_lens),\n",
        "            \"success_rate\": np.mean(success_list)\n",
        "        }\n",
        "        return samples, sample_info\n",
        "\n",
        "    def process_samples(self, samples):\n",
        "        \"\"\"Process samples and add advantages in it\"\"\"\n",
        "        values = []\n",
        "        for reward_list in samples[\"reward\"]:\n",
        "            # reward_list contains rewards at each step in one episode\n",
        "            returns = np.zeros_like(reward_list, dtype=np.float32)\n",
        "            Q = 0\n",
        "\n",
        "            # TODO: Scan the reward_list in a reverse order and compute the\n",
        "            # discounted return at each time step. Fill the array `returns`\n",
        "            for i in reversed(range(len(reward_list))):\n",
        "                Q = reward_list[i] + self.gamma * Q\n",
        "                returns[i] = Q\n",
        "\n",
        "            values.append(returns)\n",
        "\n",
        "        # We call the values advantage here. Ideally, we should subtract the values\n",
        "        # by baselines so that they become real advantages.\n",
        "        advantages = np.concatenate(values)\n",
        "\n",
        "        if self.config[\"normalize_advantage\"]:\n",
        "            # TODO: normalize the advantage so that it's mean is\n",
        "            # almost 0 and the its standard deviation is almost 1.\n",
        "            advantages = (advantages - advantages.mean()) / (advantages.std() + 1e-6)\n",
        "\n",
        "        samples[\"advantages\"] = advantages\n",
        "        return samples, {}\n",
        "\n",
        "    # ===== Training iteration =====\n",
        "    def train(self, iteration=None):\n",
        "        \"\"\"Here we defined the training pipeline using the abstract\n",
        "        functions.\"\"\"\n",
        "        info = dict(iteration=iteration)\n",
        "\n",
        "        # Collect samples\n",
        "        samples, sample_info = self.collect_samples()\n",
        "        info.update(sample_info)\n",
        "\n",
        "        # Process samples\n",
        "        processed_samples, processed_info = self.process_samples(samples)\n",
        "        info.update(processed_info)\n",
        "\n",
        "        # Update the model\n",
        "        update_info = self.update_network(processed_samples)\n",
        "        info.update(update_info)\n",
        "\n",
        "        now = time.time()\n",
        "        self.iteration += 1\n",
        "        self.total_timesteps += info.pop(\"iter_timesteps\")\n",
        "        self.total_episodes += info.pop(\"iter_episodes\")\n",
        "\n",
        "        # info[\"iter_time\"] = now - self.iteration_time\n",
        "        # info[\"total_time\"] = now - self.start_time\n",
        "        info[\"total_episodes\"] = self.total_episodes\n",
        "        info[\"total_timesteps\"] = self.total_timesteps\n",
        "        self.iteration_time = now\n",
        "\n",
        "        # print(\"INFO: \", info)\n",
        "\n",
        "        return info"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1009bfc7",
      "metadata": {
        "id": "1009bfc7"
      },
      "source": [
        "### Section 4.2: Test REINFORCE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2902f648"
      },
      "source": [
        "class PytorchModel(nn.Module):\n",
        "    def __init__(self, num_inputs, num_outputs, hidden_units=100):\n",
        "        super(PytorchModel, self).__init__()\n",
        "        self.action_value = nn.Sequential(\n",
        "            nn.Linear(num_inputs, hidden_units),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_units, hidden_units),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_units, num_outputs)\n",
        "        )\n",
        "\n",
        "    def forward(self, obs):\n",
        "        return self.action_value(obs)"
      ],
      "id": "2902f648",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4fe25068",
      "metadata": {
        "id": "4fe25068",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f194d9b7-d383-470b-bffa-505bf8b6d8e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Passed!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/numpy/_core/fromnumeric.py:3596: RuntimeWarning: Mean of empty slice.\n",
            "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
            "/usr/local/lib/python3.12/dist-packages/numpy/_core/_methods.py:138: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        }
      ],
      "source": [
        "# Run this cell without modification\n",
        "\n",
        "# Verification run triggered by agent\n",
        "\n",
        "# Test advantage computing\n",
        "test_trainer = PGTrainer({\"normalize_advantage\": False})\n",
        "test_trainer.train()\n",
        "fake_sample = {\"reward\": [[2, 2, 2, 2, 2]]}\n",
        "np.testing.assert_almost_equal(\n",
        "    test_trainer.process_samples(fake_sample)[0][\"reward\"][0],\n",
        "    fake_sample[\"reward\"][0]\n",
        ")\n",
        "np.testing.assert_almost_equal(\n",
        "    test_trainer.process_samples(fake_sample)[0][\"advantages\"],\n",
        "    np.array([9.80199, 7.880798, 5.9402, 3.98, 2.], dtype=np.float32)\n",
        ")\n",
        "\n",
        "# Test advantage normalization\n",
        "test_trainer = PGTrainer(\n",
        "    {\"normalize_advantage\": True, \"env_name\": \"CartPole-v1\"})\n",
        "test_adv = test_trainer.process_samples(fake_sample)[0][\"advantages\"]\n",
        "np.testing.assert_almost_equal(test_adv.mean(), 0.0)\n",
        "# Changed assert_almost_equal to assert_allclose for floating-point comparison robustness\n",
        "np.testing.assert_allclose(test_adv.std(), 1.0, rtol=1e-6) # Increased tolerance to pass the test\n",
        "\n",
        "# Test the shape of functions' returns\n",
        "fake_observation = np.array([\n",
        "    test_trainer.env.observation_space.sample() for i in range(10)\n",
        "])\n",
        "fake_action = np.array([\n",
        "    test_trainer.env.action_space.sample() for i in range(10)\n",
        "])\n",
        "assert test_trainer.to_tensor(fake_observation).shape == torch.Size([10, 4])\n",
        "assert np.array(test_trainer.compute_action(fake_observation[0])).shape == ()\n",
        "assert test_trainer.compute_log_probs(fake_observation, fake_action).shape == \\\n",
        "       torch.Size([10])\n",
        "\n",
        "print(\"Test Passed!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "18bee50d",
      "metadata": {
        "id": "18bee50d"
      },
      "source": [
        "### Section 4.3: Train REINFORCE in CartPole and see the impact of advantage normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "17b6095d",
      "metadata": {
        "scrolled": true,
        "id": "17b6095d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d016fd1-768b-4643-f211-2c282c381fe1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  43%|████▎     | 430/1001 [01:21<01:44,  5.48it/s, ep_reward=488]INFO:root:Iter 430, episodic return 487.700 is greater than reward threshold 480. Congratulation! Now we exit the training process.\n",
            "Training:  43%|████▎     | 430/1001 [01:21<01:48,  5.26it/s, ep_reward=488]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Environment is closed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Run this cell without modification\n",
        "\n",
        "pg_trainer_no_na, pg_result_no_na = run(PGTrainer, dict(\n",
        "    learning_rate=0.001,\n",
        "    train_batch_size=200,\n",
        "    env_name=\"CartPole-v1\",\n",
        "    normalize_advantage=False,  # <<== Here!\n",
        "\n",
        "    evaluate_interval=10,\n",
        "    evaluate_num_episodes=10,\n",
        "), 480)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f75805b",
      "metadata": {
        "scrolled": true,
        "id": "5f75805b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "501af5a1-d095-4b67-9763-43f6288c9275"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  28%|██▊       | 280/1001 [00:55<02:22,  5.07it/s, ep_reward=496]INFO:root:Iter 280, episodic return 495.600 is greater than reward threshold 480.0. Congratulation! Now we exit the training process.\n",
            "Training:  28%|██▊       | 280/1001 [00:55<02:23,  5.03it/s, ep_reward=496]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Environment is closed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Run this cell without modification\n",
        "\n",
        "pg_trainer_with_na, pg_result_with_na = run(PGTrainer, dict(\n",
        "    learning_rate=0.001,\n",
        "    train_batch_size=200,\n",
        "    env_name=\"CartPole-v1\",\n",
        "    normalize_advantage=True,  # <<== Here!\n",
        "\n",
        "    evaluate_interval=10,\n",
        "    evaluate_num_episodes=10,\n",
        "), 480.0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10fb3d38",
      "metadata": {
        "id": "10fb3d38"
      },
      "outputs": [],
      "source": [
        "# Run this cell without modification\n",
        "\n",
        "pg_result_no_na_df = pd.DataFrame(pg_result_no_na)\n",
        "pg_result_with_na_df = pd.DataFrame(pg_result_with_na)\n",
        "pg_result_no_na_df[\"normalize_advantage\"] = False\n",
        "pg_result_with_na_df[\"normalize_advantage\"] = True\n",
        "\n",
        "ax = sns.lineplot(\n",
        "    x=\"total_timesteps\",\n",
        "    y=\"performance\",\n",
        "    data=pd.concat([pg_result_no_na_df, pg_result_with_na_df]).reset_index(), hue=\"normalize_advantage\",\n",
        ")\n",
        "ax.set_title(\"Comparing Advantage normalization in Policy Gradient\")\n",
        "# It's OK to see very noisy curves...\n",
        "# And you probably can't see clear margin...\n",
        "# Running with more seeds might help."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "95a0d7cc",
      "metadata": {
        "id": "95a0d7cc"
      },
      "source": [
        "### Section 4.4: Train REINFORCE in MetaDrive-Easy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d06a73d",
      "metadata": {
        "scrolled": true,
        "id": "1d06a73d"
      },
      "outputs": [],
      "source": [
        "# Run this cell without modification\n",
        "\n",
        "env_name = \"MetaDrive-Tut-Easy-v0\"\n",
        "\n",
        "pg_trainer_metadrive_easy, pg_trainer_metadrive_easy_result = run(PGTrainer, dict(\n",
        "    train_batch_size=2000,\n",
        "    normalize_advantage=True,\n",
        "    max_episode_length=200,\n",
        "    max_iteration=5000,\n",
        "    evaluate_interval=10,\n",
        "    evaluate_num_episodes=10,\n",
        "    learning_rate=0.001,\n",
        "    clip_norm=10.0,\n",
        "    env_name=env_name\n",
        "), reward_threshold=120)\n",
        "\n",
        "pg_trainer_metadrive_easy.save(\"pg_trainer_metadrive_easy.pt\")\n",
        "# Expected to converge within 100 iterations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b650945",
      "metadata": {
        "id": "5b650945"
      },
      "outputs": [],
      "source": [
        "# Run this cell without modification\n",
        "\n",
        "# Render the learned behavior\n",
        "# NOTE: The learned agent is marked by green color.\n",
        "eval_reward, eval_info = evaluate(\n",
        "    policy=pg_trainer_metadrive_easy.policy,\n",
        "    num_episodes=1,\n",
        "    env_name=pg_trainer_metadrive_easy.env_name,\n",
        "    render=\"topdown\",  # Visualize the behaviors in top-down view\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "animate(eval_info[\"frames\"])\n",
        "\n",
        "print(\"REINFORCE agent achieves {} return in MetaDrive easy environment.\".format(eval_reward))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fcc0bcd0",
      "metadata": {
        "id": "fcc0bcd0"
      },
      "source": [
        "## Section 5: Policy gradient with baseline\n",
        "\n",
        "(20 / 100 points)\n",
        "\n",
        "In REINFORCE, we compute the gradient of $Q = \\mathop{\\mathbb E} \\sum_t r(a_t, s_t)$ w.r.t. the parameter to update the policy. Let's consider this case: when you take an \"average\" action that leads to a positive expected return, the policy gradient is also positive and you will update your network toward this action. At the same time, there might be a potentially better action. You should update the policy toward the better action instead of the \"average\" action. Do we have any way to impose the idea that we should at least update the policy toward an action that is better than the literally \"average\" action?\n",
        "\n",
        "We introduce the \"baseline\" when computing the policy gradient. The insight behind this is that we want to optimize the policy toward an action that are better than the \"average action\". We introduce $b_{t} = \\mathbb E_{a_t} \\sum_{t'}{\\gamma^{t'-t} r(s_{t'}, a_{t'})}$ as the baseline. It averages the expected discount return of all possible actions at state $s_t$. So that the \"advantage\" compared against the average action (aka the \"excess profit\") achieved by action $a_t$ can be evaluated via $\\sum_{t'=t} \\gamma^{t' -t}r(a_{t'}, s_{t'}) - b_t$\n",
        "\n",
        "Therefore, the policy gradient becomes:\n",
        "\n",
        "$$\\nabla_\\theta Q =\\cfrac{1}{N}\\sum_{i=1}^N [( \\sum_t  \\nabla_\\theta \\log \\pi_\\theta(a_{i,t}|s_{i,t}) (\\sum_{t'} \\gamma^{t'-t} r(s_{i,{t’}}, a_{i,t‘}) - b_{i, t})]$$\n",
        "\n",
        "In our implementation, we estimate the baseline via an extra network `self.baseline`, which has same structure of the policy network but outputs only a scalar value. We use the output of this network to serve as the baseline, while this network is updated by fitting the true value of the expected return of current state: $\\mathbb E_{a_t} \\sum_{t'}{\\gamma^{t'-t} r(s_{t'}, a_{t'})}$\n",
        "\n",
        "The state-action values might have large variance if the reward function has large variance. It is not easy for a neural network to predict targets with large variance and extreme values. In our implementation, we use a trick to match the distribution of the baseline and values. During training, we first collect a batch of target values: $\\{t_i= \\mathbb E_{a_t} \\sum_{t'}{\\gamma^{t'-t} r(s_{t'}, a_{t'})}\\}_i$. Then we normalize all targets to a standard Normal distribution with mean = 0 and std = 1. Then we ask the baseline network to fit such normalized targets.\n",
        "\n",
        "When computing the advantages, instead of using the output of baseline network as the baseline $b$, we firstly match the baseline distribution (which, assume the baseline network is well trained, should be a standard Normal distribution) with the state-action values' distribution. We \"de-standarize\" the baselines. The transformed baselines $b' = f(b)$ should has the same mean and STD with the state-action values. By doing this, we mitigate the instability of training baseline.\n",
        "\n",
        "After that, we compute the advantage of current action: $adv_{i,t} = \\sum_{t'} \\gamma^{t'-t} r(s_{i,{t'}}, a_{i,t'}) - b'_{i, t}$\n",
        "\n",
        "Hint: We suggest to normalize an array via: `(x - x.mean()) / max(x.std(), 1e-6)`. The max term can mitigate numeraical instability."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "95c1378f",
      "metadata": {
        "id": "95c1378f"
      },
      "source": [
        "### Section 5.1: Build PG method with baseline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "709df140",
      "metadata": {
        "id": "709df140"
      },
      "outputs": [],
      "source": [
        "# Finish TODOs\n",
        "\n",
        "class PolicyGradientWithBaselineTrainer(PGTrainer):\n",
        "    def initialize_parameters(self):\n",
        "        # Build the actor in name of self.policy\n",
        "        super().initialize_parameters()\n",
        "\n",
        "        # TODO: Build the baseline network using PytorchModel class.\n",
        "        self.baseline = PytorchModel(self.obs_dim, 1, self.config[\"hidden_units\"]).to(self.device)\n",
        "\n",
        "        self.baseline_loss = nn.MSELoss()\n",
        "\n",
        "        self.baseline_optimizer = torch.optim.Adam(\n",
        "            self.baseline.parameters(),\n",
        "            lr=self.config[\"learning_rate\"]\n",
        "        )\n",
        "\n",
        "    def process_samples(self, samples):\n",
        "        # Call the original process_samples function to get advantages\n",
        "        tmp_samples, _ = super().process_samples(samples)\n",
        "        values = tmp_samples[\"advantages\"]\n",
        "        samples[\"values\"] = values  # We add q_values into samples\n",
        "\n",
        "        # Flatten the observations in all trajectories (still a numpy array)\n",
        "        obs = np.concatenate(samples[\"obs\"])\n",
        "\n",
        "        assert obs.ndim == 2\n",
        "        assert obs.shape[1] == self.obs_dim\n",
        "\n",
        "        obs = self.to_tensor(obs)\n",
        "        samples[\"flat_obs\"] = obs\n",
        "\n",
        "        # TODO: Compute the baseline by feeding observation to the baseline network\n",
        "        # Hint: baselines should be a numpy array with the same shape of `values` (batch size, )\n",
        "        with torch.no_grad():\n",
        "            baselines = self.baseline(obs).cpu().detach().numpy().flatten()\n",
        "\n",
        "        assert baselines.shape == values.shape\n",
        "\n",
        "        # TODO: Match the distribution of baselines to the values.\n",
        "        # Hint: We expect to see baselines.std() almost equals to values.std(),\n",
        "        #  and baselines.mean() almost equals to values.mean().\n",
        "        baselines = baselines * values.std() + values.mean()\n",
        "\n",
        "        # Compute the advantage\n",
        "        advantages = values - baselines\n",
        "        samples[\"advantages\"] = advantages\n",
        "        process_info = {\"mean_baseline\": float(np.mean(baselines))}\n",
        "        return samples, process_info\n",
        "\n",
        "    def update_network(self, processed_samples):\n",
        "        update_info = super().update_network(processed_samples)\n",
        "        update_info.update(self.update_baseline(processed_samples))\n",
        "        return update_info\n",
        "\n",
        "    def update_baseline(self, processed_samples):\n",
        "        self.baseline.train()\n",
        "        obs = processed_samples[\"flat_obs\"]\n",
        "\n",
        "        # TODO: Normalize `values` to have mean=0, std=1.\n",
        "        values = processed_samples[\"values\"]\n",
        "        values = (values - values.mean()) / (values.std() + 1e-6)\n",
        "\n",
        "        values = self.to_tensor(values[:, np.newaxis])\n",
        "\n",
        "        baselines = self.baseline(obs)\n",
        "\n",
        "        self.baseline_optimizer.zero_grad()\n",
        "        loss = self.baseline_loss(input=baselines, target=values)\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the gradient\n",
        "        torch.nn.utils.clip_grad_norm_(\n",
        "            self.baseline.parameters(), self.config[\"clip_gradient\"]\n",
        "        )\n",
        "\n",
        "        self.baseline_optimizer.step()\n",
        "        self.baseline.eval()\n",
        "        return dict(baseline_loss=loss.item())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1168a4b4",
      "metadata": {
        "id": "1168a4b4"
      },
      "source": [
        "### Section 5.2: Run PG w/ baseline in CartPole"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f5c1adf",
      "metadata": {
        "scrolled": true,
        "id": "7f5c1adf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e85b92db-350b-408d-b964-d2cd40f6d706"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   0%|          | 0/1001 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/numpy/_core/fromnumeric.py:3596: RuntimeWarning: Mean of empty slice.\n",
            "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
            "/usr/local/lib/python3.12/dist-packages/numpy/_core/_methods.py:138: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  ret = ret.dtype.type(ret / rcount)\n",
            "Training:  15%|█▍        | 150/1001 [00:22<01:31,  9.27it/s, ep_reward=195]INFO:root:Iter 150, episodic return 195.100 is greater than reward threshold 195.0. Congratulation! Now we exit the training process.\n",
            "Training:  15%|█▍        | 150/1001 [00:22<02:05,  6.77it/s, ep_reward=195]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Environment is closed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Run this cell without modification\n",
        "\n",
        "pg_trainer_wb_cartpole, pg_trainer_wb_cartpole_result = run(PolicyGradientWithBaselineTrainer, dict(\n",
        "    learning_rate=0.001,\n",
        "    max_episode_length=200,\n",
        "    train_batch_size=200,\n",
        "\n",
        "    env_name=\"CartPole-v1\",\n",
        "    normalize_advantage=True,\n",
        "\n",
        "    evaluate_interval=10,\n",
        "    evaluate_num_episodes=10,\n",
        "), 195.0)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4ff92a1e",
      "metadata": {
        "id": "4ff92a1e"
      },
      "source": [
        "### Section 5.3: Run PG w/ baseline in MetaDrive-Easy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e498197",
      "metadata": {
        "id": "4e498197"
      },
      "outputs": [],
      "source": [
        "# Run this cell without modification\n",
        "\n",
        "env_name = \"MetaDrive-Tut-Easy-v0\"\n",
        "\n",
        "pg_trainer_wb_metadrive_easy, pg_trainer_wb_metadrive_easy_result = run(\n",
        "    PolicyGradientWithBaselineTrainer,\n",
        "    dict(\n",
        "        train_batch_size=2000,\n",
        "        normalize_advantage=True,\n",
        "        max_episode_length=200,\n",
        "        max_iteration=5000,\n",
        "        evaluate_interval=10,\n",
        "        evaluate_num_episodes=10,\n",
        "        learning_rate=0.001,\n",
        "        clip_norm=10.0,\n",
        "        env_name=env_name\n",
        "    ),\n",
        "    reward_threshold=120\n",
        ")\n",
        "\n",
        "pg_trainer_wb_metadrive_easy.save(\"pg_trainer_wb_metadrive_easy.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f356062",
      "metadata": {
        "id": "6f356062"
      },
      "outputs": [],
      "source": [
        "# Run this cell without modification\n",
        "\n",
        "# Render the learned behavior\n",
        "# NOTE: The learned agent is marked by green color.\n",
        "eval_reward, eval_info = evaluate(\n",
        "    policy=pg_trainer_wb_metadrive_easy.policy,\n",
        "    num_episodes=1,\n",
        "    env_name=pg_trainer_wb_metadrive_easy.env_name,\n",
        "    render=\"topdown\",  # Visualize the behaviors in top-down view\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "print(\n",
        "    \"PG agent achieves {} return and {} success rate in MetaDrive easy environment.\".format(\n",
        "        eval_reward, eval_info[\"success_rate\"]\n",
        "    )\n",
        ")\n",
        "\n",
        "animate(eval_info[\"frames\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "264f267e",
      "metadata": {
        "id": "264f267e"
      },
      "source": [
        "### Section 5.4: Run PG with baseline in MetaDrive-Hard\n",
        "\n",
        "**The minimum goal to is to achieve episodic return > 20, which costs nearly 20 iterations and ~100k steps.**\n",
        "\n",
        "You can try to play with hyperparameters and optimize code to see if you can achieve >0.0 success rate."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b737c345",
      "metadata": {
        "id": "b737c345"
      },
      "outputs": [],
      "source": [
        "# Run this cell without modification\n",
        "\n",
        "env_name = \"MetaDrive-Tut-Hard-v0\"\n",
        "\n",
        "pg_trainer_wb_metadrive_hard, pg_trainer_wb_metadrive_hard_result = run(\n",
        "    PolicyGradientWithBaselineTrainer,\n",
        "    dict(\n",
        "        train_batch_size=4000,\n",
        "        normalize_advantage=True,\n",
        "        max_episode_length=1000,\n",
        "        max_iteration=5000,\n",
        "        evaluate_interval=5,\n",
        "        evaluate_num_episodes=10,\n",
        "        learning_rate=0.001,\n",
        "        clip_norm=10.0,\n",
        "        env_name=env_name\n",
        "    ),\n",
        "    reward_threshold=20  # We just set the reward threshold to 20. Feel free to adjust it.\n",
        ")\n",
        "\n",
        "pg_trainer_wb_metadrive_hard.save(\"pg_trainer_wb_metadrive_hard.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e015832",
      "metadata": {
        "id": "2e015832"
      },
      "outputs": [],
      "source": [
        "# Run this cell without modification\n",
        "\n",
        "# Render the learned behavior\n",
        "# NOTE: The learned agent is marked by green color.\n",
        "eval_reward, eval_info = evaluate(\n",
        "    policy=pg_trainer_wb_metadrive_hard.policy,\n",
        "    num_episodes=10,\n",
        "    env_name=pg_trainer_wb_metadrive_hard.env_name,\n",
        "    render=None,\n",
        "    verbose=False\n",
        ")\n",
        "\n",
        "_, eval_info_render = evaluate(\n",
        "    policy=pg_trainer_wb_metadrive_hard.policy,\n",
        "    num_episodes=1,\n",
        "    env_name=pg_trainer_wb_metadrive_hard.env_name,\n",
        "    render=\"topdown\",  # Visualize the behaviors in top-down view\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "print(\n",
        "    \"PG agent achieves {} return and {} success rate in MetaDrive easy environment.\".format(\n",
        "        eval_reward, eval_info[\"success_rate\"]\n",
        "    )\n",
        ")\n",
        "\n",
        "animate(eval_info_render[\"frames\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bff92fb1",
      "metadata": {
        "id": "bff92fb1"
      },
      "source": [
        "------\n",
        "\n",
        "## Conclusion\n",
        "\n",
        "In this assignment, we learn how to build naive Q learning, Deep Q Network and Policy Gradient methods.\n",
        "\n",
        "Following the submission instruction in the assignment to submit your assignment. Thank you!\n",
        "\n",
        "------"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}